{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST handwritten digits\n",
    "\n",
    "MLP - MNIST 손글씨 숫자 인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Dataset\n",
    "\n",
    "MNIST dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()    # load mnist data\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset split\n",
    "\n",
    "train dataset에 60000개 데이터가 있으므로, 랜덤하게 split하여 3만개의 학습데이터만 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train is [30000    28    28]\n",
      "shape of y_train is [30000]\n",
      "shape of x_test is [10000    28    28]\n",
      "shape of y_test is [10000]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "rand_selected = random.sample([x for x in range(0, len(x_train))], 30000)\n",
    "x_train = x_train[rand_selected]\n",
    "y_train = y_train[rand_selected]\n",
    "\n",
    "print(f\"shape of x_train is {tf.shape(x_train)}\")\n",
    "print(f\"shape of y_train is {tf.shape(y_train)}\")\n",
    "print(f\"shape of x_test is {tf.shape(x_test)}\")\n",
    "print(f\"shape of y_test is {tf.shape(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training data preprocessing\n",
    "\n",
    "### 3.1. Data Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(x_train)\n",
    "std = np.std(x_train)\n",
    "\n",
    "x_train = (x_train - mean)/std\n",
    "x_test = (x_test - mean)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Data enhance - By shifting and rotating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of shifted_x_train is (240000, 28, 28)\n",
      "shape of shifted_y_train is (240000,)\n"
     ]
    }
   ],
   "source": [
    "from scipy.ndimage.interpolation import shift\n",
    "\n",
    "x_enhanced = []\n",
    "y_enhanced = []\n",
    "\n",
    "shifting_list = [\n",
    "    [0, 1],\n",
    "    [1, 0], \n",
    "    [-1, 0],\n",
    "    [0, -1],\n",
    "    [1, 1],\n",
    "    [-1, 1],\n",
    "    [1, -1],\n",
    "    [-1, -1]\n",
    "]\n",
    "\n",
    "for x_shift, y_shift in shifting_list:\n",
    "     for image, label in zip(x_train, y_train):\n",
    "        shifted_image = shift(image, [y_shift, x_shift])\n",
    "        shifted_image.reshape([-1])\n",
    "        x_enhanced.append(shifted_image)\n",
    "        y_enhanced.append(label)\n",
    "\n",
    "shifted_x_train = np.array(x_enhanced)\n",
    "shifted_y_train = np.array(y_enhanced)\n",
    "\n",
    "print(f\"shape of shifted_x_train is {np.shape(shifted_x_train)}\")\n",
    "print(f\"shape of shifted_y_train is {np.shape(shifted_y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of rotated_x_train is (180000, 28, 28)\n",
      "shape of rotated_y_train is (180000,)\n"
     ]
    }
   ],
   "source": [
    "import imutils\n",
    "\n",
    "x_enhanced = []\n",
    "y_enhanced = []\n",
    "\n",
    "rotating_list = [10, 20, 30]\n",
    "\n",
    "for rotate_angle in rotating_list:\n",
    "    for image, label in zip(x_train, y_train):\n",
    "        positive_rotated_image = imutils.rotate(image, rotate_angle)\n",
    "        negative_rotated_image = imutils.rotate(image, -rotate_angle)\n",
    "        x_enhanced.append(positive_rotated_image)\n",
    "        y_enhanced.append(label)\n",
    "        x_enhanced.append(negative_rotated_image)\n",
    "        y_enhanced.append(label)\n",
    "\n",
    "rotated_x_train = np.array(x_enhanced)\n",
    "rotated_y_train = np.array(y_enhanced)\n",
    "\n",
    "print(f\"shape of rotated_x_train is {np.shape(rotated_x_train)}\")\n",
    "print(f\"shape of rotated_y_train is {np.shape(rotated_y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train is (450000, 28, 28)\n",
      "shape of y_train is (450000,)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.append(x_train, shifted_x_train, 0)\n",
    "x_train = np.append(x_train, rotated_x_train, 0)\n",
    "shifted_x_train = []\n",
    "rotated_x_train = []\n",
    "\n",
    "y_train = np.append(y_train, shifted_y_train, 0)\n",
    "y_train = np.append(y_train, rotated_y_train, 0)\n",
    "shifted_y_train = []\n",
    "rotated_y_train = []\n",
    "\n",
    "rand_selected = random.sample([x for x in range(0, len(x_train))], len(x_train))\n",
    "x_train = np.array(x_train)[rand_selected]\n",
    "y_train = np.array(y_train)[rand_selected]\n",
    "\n",
    "print(f\"shape of x_train is {np.shape(x_train)}\")\n",
    "print(f\"shape of y_train is {np.shape(y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel = random.randint(0, len(x_train))\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "train_img = np.reshape(x_train[sel], [28, 28])\n",
    "plt.imshow(train_img, cmap='Greys')\n",
    "plt.show()\n",
    "\n",
    "y_train[sel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s\\anaconda3\\envs\\tf3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(786, activation='relu'),\n",
    "    tf.keras.layers.Dense(1024, activation='relu'),\n",
    "    tf.keras.layers.Dense(2048, activation='relu'),\n",
    "    tf.keras.layers.Dense(4096, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(4096, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(2048, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(lr=0.0008)\n",
    "los = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "model.compile(optimizer=opt,\n",
    "              loss=los,\n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "3516/3516 [==============================] - 155s 43ms/step - loss: 0.1639 - sparse_categorical_accuracy: 0.9517 - val_loss: 0.1114 - val_sparse_categorical_accuracy: 0.9716\n",
      "Epoch 2/200\n",
      "3516/3516 [==============================] - 150s 43ms/step - loss: 0.0816 - sparse_categorical_accuracy: 0.9778 - val_loss: 0.0816 - val_sparse_categorical_accuracy: 0.9769\n",
      "Epoch 3/200\n",
      "3516/3516 [==============================] - 155s 44ms/step - loss: 0.0453 - sparse_categorical_accuracy: 0.9866 - val_loss: 0.0595 - val_sparse_categorical_accuracy: 0.9861\n",
      "Epoch 4/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0409 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.0454 - val_sparse_categorical_accuracy: 0.9870\n",
      "Epoch 5/200\n",
      "3516/3516 [==============================] - 156s 44ms/step - loss: 0.0274 - sparse_categorical_accuracy: 0.9918 - val_loss: 0.0786 - val_sparse_categorical_accuracy: 0.9807\n",
      "Epoch 6/200\n",
      "3516/3516 [==============================] - 157s 45ms/step - loss: 0.0220 - sparse_categorical_accuracy: 0.9934 - val_loss: 33.4142 - val_sparse_categorical_accuracy: 0.9736\n",
      "Epoch 7/200\n",
      "3516/3516 [==============================] - 157s 45ms/step - loss: 0.0197 - sparse_categorical_accuracy: 0.9941 - val_loss: 0.0668 - val_sparse_categorical_accuracy: 0.9855\n",
      "Epoch 8/200\n",
      "3516/3516 [==============================] - 155s 44ms/step - loss: 0.0161 - sparse_categorical_accuracy: 0.9952 - val_loss: 0.9264 - val_sparse_categorical_accuracy: 0.9865\n",
      "Epoch 9/200\n",
      "3516/3516 [==============================] - 157s 45ms/step - loss: 0.0460 - sparse_categorical_accuracy: 0.9889 - val_loss: 487.1641 - val_sparse_categorical_accuracy: 0.9863\n",
      "Epoch 10/200\n",
      "3516/3516 [==============================] - 157s 45ms/step - loss: 0.0148 - sparse_categorical_accuracy: 0.9954 - val_loss: 0.0659 - val_sparse_categorical_accuracy: 0.9864\n",
      "Epoch 11/200\n",
      "3516/3516 [==============================] - 157s 45ms/step - loss: 0.0121 - sparse_categorical_accuracy: 0.9963 - val_loss: 0.0641 - val_sparse_categorical_accuracy: 0.9858\n",
      "Epoch 12/200\n",
      "3516/3516 [==============================] - 156s 44ms/step - loss: 0.0119 - sparse_categorical_accuracy: 0.9965 - val_loss: 402.8019 - val_sparse_categorical_accuracy: 0.9890\n",
      "Epoch 13/200\n",
      "3516/3516 [==============================] - 157s 45ms/step - loss: 0.0111 - sparse_categorical_accuracy: 0.9968 - val_loss: 7.7001 - val_sparse_categorical_accuracy: 0.9869\n",
      "Epoch 14/200\n",
      "3516/3516 [==============================] - 157s 45ms/step - loss: 0.0092 - sparse_categorical_accuracy: 0.9973 - val_loss: 152.8742 - val_sparse_categorical_accuracy: 0.9882\n",
      "Epoch 15/200\n",
      "3516/3516 [==============================] - 153s 43ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9975 - val_loss: 0.5760 - val_sparse_categorical_accuracy: 0.9865\n",
      "Epoch 16/200\n",
      "3516/3516 [==============================] - 156s 44ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9978 - val_loss: 95.6817 - val_sparse_categorical_accuracy: 0.9877\n",
      "Epoch 17/200\n",
      "3516/3516 [==============================] - 156s 44ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9980 - val_loss: 2.4024 - val_sparse_categorical_accuracy: 0.9873\n",
      "Epoch 18/200\n",
      "3516/3516 [==============================] - 157s 45ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0763 - val_sparse_categorical_accuracy: 0.9884\n",
      "Epoch 19/200\n",
      "3516/3516 [==============================] - 157s 45ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9982 - val_loss: 15.9387 - val_sparse_categorical_accuracy: 0.9870\n",
      "Epoch 20/200\n",
      "3516/3516 [==============================] - 157s 45ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9983 - val_loss: 366.7099 - val_sparse_categorical_accuracy: 0.9878\n",
      "Epoch 21/200\n",
      "3516/3516 [==============================] - 157s 45ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9984 - val_loss: 5689.1011 - val_sparse_categorical_accuracy: 0.9874\n",
      "Epoch 22/200\n",
      "3516/3516 [==============================] - 157s 45ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9986 - val_loss: 5242.0806 - val_sparse_categorical_accuracy: 0.9876\n",
      "Epoch 23/200\n",
      "3516/3516 [==============================] - 156s 44ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9986 - val_loss: 829.7619 - val_sparse_categorical_accuracy: 0.9832\n",
      "Epoch 24/200\n",
      "3516/3516 [==============================] - 157s 45ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9986 - val_loss: 1381.5134 - val_sparse_categorical_accuracy: 0.9881\n",
      "Epoch 25/200\n",
      "3516/3516 [==============================] - 156s 44ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9987 - val_loss: 331.2173 - val_sparse_categorical_accuracy: 0.9894\n",
      "Epoch 26/200\n",
      "3516/3516 [==============================] - 156s 44ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9988 - val_loss: 2062.0898 - val_sparse_categorical_accuracy: 0.9873\n",
      "Epoch 27/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9988 - val_loss: 1367.2219 - val_sparse_categorical_accuracy: 0.9884\n",
      "Epoch 28/200\n",
      "3516/3516 [==============================] - 157s 45ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9987 - val_loss: 795.3657 - val_sparse_categorical_accuracy: 0.9882\n",
      "Epoch 29/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9989 - val_loss: 9983.5146 - val_sparse_categorical_accuracy: 0.9886\n",
      "Epoch 30/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9990 - val_loss: 842.8039 - val_sparse_categorical_accuracy: 0.9894\n",
      "Epoch 31/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9991 - val_loss: 124.2607 - val_sparse_categorical_accuracy: 0.9883\n",
      "Epoch 32/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0104 - sparse_categorical_accuracy: 0.9990 - val_loss: 31.6713 - val_sparse_categorical_accuracy: 0.9894\n",
      "Epoch 33/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0029 - sparse_categorical_accuracy: 0.9992 - val_loss: 824.0040 - val_sparse_categorical_accuracy: 0.9865\n",
      "Epoch 34/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9991 - val_loss: 729.6958 - val_sparse_categorical_accuracy: 0.9866\n",
      "Epoch 35/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9991 - val_loss: 17056.6328 - val_sparse_categorical_accuracy: 0.9871\n",
      "Epoch 36/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0032 - sparse_categorical_accuracy: 0.9992 - val_loss: 2136.6455 - val_sparse_categorical_accuracy: 0.9883\n",
      "Epoch 37/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9991 - val_loss: 2485.1465 - val_sparse_categorical_accuracy: 0.9889\n",
      "Epoch 38/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0032 - sparse_categorical_accuracy: 0.9992 - val_loss: 3397.7771 - val_sparse_categorical_accuracy: 0.9885\n",
      "Epoch 39/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0034 - sparse_categorical_accuracy: 0.9993 - val_loss: 424.2791 - val_sparse_categorical_accuracy: 0.9906\n",
      "Epoch 40/200\n",
      "3516/3516 [==============================] - 155s 44ms/step - loss: 0.0030 - sparse_categorical_accuracy: 0.9993 - val_loss: 1546.6687 - val_sparse_categorical_accuracy: 0.9890 loss: 0.0030 - sp\n",
      "Epoch 41/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0031 - sparse_categorical_accuracy: 0.9993 - val_loss: 0.3252 - val_sparse_categorical_accuracy: 0.9888\n",
      "Epoch 42/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0027 - sparse_categorical_accuracy: 0.9993 - val_loss: 197.0490 - val_sparse_categorical_accuracy: 0.9873\n",
      "Epoch 43/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0029 - sparse_categorical_accuracy: 0.9993 - val_loss: 0.0859 - val_sparse_categorical_accuracy: 0.9876\n",
      "Epoch 44/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0025 - sparse_categorical_accuracy: 0.9994 - val_loss: 283.9232 - val_sparse_categorical_accuracy: 0.9893\n",
      "Epoch 45/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0022 - sparse_categorical_accuracy: 0.9995 - val_loss: 0.1178 - val_sparse_categorical_accuracy: 0.9891\n",
      "Epoch 46/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0034 - sparse_categorical_accuracy: 0.9993 - val_loss: 835.1567 - val_sparse_categorical_accuracy: 0.9896\n",
      "Epoch 47/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0024 - sparse_categorical_accuracy: 0.9994 - val_loss: 1870.4091 - val_sparse_categorical_accuracy: 0.9888\n",
      "Epoch 48/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0027 - sparse_categorical_accuracy: 0.9993 - val_loss: 1945.5258 - val_sparse_categorical_accuracy: 0.9897\n",
      "Epoch 49/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0023 - sparse_categorical_accuracy: 0.9994 - val_loss: 463.7016 - val_sparse_categorical_accuracy: 0.9883\n",
      "Epoch 50/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0034 - sparse_categorical_accuracy: 0.9993 - val_loss: 12.9880 - val_sparse_categorical_accuracy: 0.9894ss: 0.0035 - sparse_categorical\n",
      "Epoch 51/200\n",
      "3516/3516 [==============================] - 157s 45ms/step - loss: 0.0020 - sparse_categorical_accuracy: 0.9995 - val_loss: 2531.2942 - val_sparse_categorical_accuracy: 0.9883\n",
      "Epoch 52/200\n",
      "3516/3516 [==============================] - 157s 45ms/step - loss: 0.0027 - sparse_categorical_accuracy: 0.9994 - val_loss: 7.8626 - val_sparse_categorical_accuracy: 0.9889\n",
      "Epoch 53/200\n",
      "3516/3516 [==============================] - 157s 45ms/step - loss: 0.0021 - sparse_categorical_accuracy: 0.9995 - val_loss: 86.6578 - val_sparse_categorical_accuracy: 0.9900\n",
      "Epoch 54/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0023 - sparse_categorical_accuracy: 0.9995 - val_loss: 6780.9487 - val_sparse_categorical_accuracy: 0.9882\n",
      "Epoch 55/200\n",
      "3516/3516 [==============================] - 157s 45ms/step - loss: 0.0030 - sparse_categorical_accuracy: 0.9994 - val_loss: 0.0744 - val_sparse_categorical_accuracy: 0.9886\n",
      "Epoch 56/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0017 - sparse_categorical_accuracy: 0.9996 - val_loss: 0.0987 - val_sparse_categorical_accuracy: 0.9897\n",
      "Epoch 57/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0024 - sparse_categorical_accuracy: 0.9995 - val_loss: 14608.5332 - val_sparse_categorical_accuracy: 0.9886\n",
      "Epoch 58/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0016 - sparse_categorical_accuracy: 0.9996 - val_loss: 542.2712 - val_sparse_categorical_accuracy: 0.9882\n",
      "Epoch 59/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0025 - sparse_categorical_accuracy: 0.9995 - val_loss: 0.1152 - val_sparse_categorical_accuracy: 0.9889\n",
      "Epoch 60/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0025 - sparse_categorical_accuracy: 0.9995 - val_loss: 0.1345 - val_sparse_categorical_accuracy: 0.9892\n",
      "Epoch 61/200\n",
      "3516/3516 [==============================] - 154s 44ms/step - loss: 0.0023 - sparse_categorical_accuracy: 0.9995 - val_loss: 0.2236 - val_sparse_categorical_accuracy: 0.9900\n",
      "Epoch 62/200\n",
      "3516/3516 [==============================] - 155s 44ms/step - loss: 0.0021 - sparse_categorical_accuracy: 0.9995 - val_loss: 10717.2500 - val_sparse_categorical_accuracy: 0.9907\n",
      "Epoch 63/200\n",
      "3516/3516 [==============================] - 154s 44ms/step - loss: 0.0020 - sparse_categorical_accuracy: 0.9995 - val_loss: 0.1387 - val_sparse_categorical_accuracy: 0.9888\n",
      "Epoch 64/200\n",
      "3516/3516 [==============================] - 154s 44ms/step - loss: 0.0022 - sparse_categorical_accuracy: 0.9995 - val_loss: 7.3736 - val_sparse_categorical_accuracy: 0.9892\n",
      "Epoch 65/200\n",
      "3516/3516 [==============================] - 154s 44ms/step - loss: 0.0028 - sparse_categorical_accuracy: 0.9995 - val_loss: 690.6861 - val_sparse_categorical_accuracy: 0.9900\n",
      "Epoch 66/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0019 - sparse_categorical_accuracy: 0.9996 - val_loss: 0.0875 - val_sparse_categorical_accuracy: 0.9903\n",
      "Epoch 67/200\n",
      "3516/3516 [==============================] - 161s 46ms/step - loss: 0.0023 - sparse_categorical_accuracy: 0.9996 - val_loss: 906.5092 - val_sparse_categorical_accuracy: 0.9890\n",
      "Epoch 68/200\n",
      "3516/3516 [==============================] - 156s 44ms/step - loss: 0.0017 - sparse_categorical_accuracy: 0.9996 - val_loss: 3315.0220 - val_sparse_categorical_accuracy: 0.9884\n",
      "Epoch 69/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0021 - sparse_categorical_accuracy: 0.9996 - val_loss: 203.8761 - val_sparse_categorical_accuracy: 0.9894\n",
      "Epoch 70/200\n",
      "3516/3516 [==============================] - 157s 45ms/step - loss: 0.0017 - sparse_categorical_accuracy: 0.9996 - val_loss: 1.2443 - val_sparse_categorical_accuracy: 0.9882\n",
      "Epoch 71/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0017 - sparse_categorical_accuracy: 0.9996 - val_loss: 0.1553 - val_sparse_categorical_accuracy: 0.9891\n",
      "Epoch 72/200\n",
      "3516/3516 [==============================] - 157s 45ms/step - loss: 0.0022 - sparse_categorical_accuracy: 0.9996 - val_loss: 4877.5967 - val_sparse_categorical_accuracy: 0.9888\n",
      "Epoch 73/200\n",
      "3516/3516 [==============================] - 157s 45ms/step - loss: 0.0019 - sparse_categorical_accuracy: 0.9996 - val_loss: 0.1408 - val_sparse_categorical_accuracy: 0.9884\n",
      "Epoch 74/200\n",
      "3516/3516 [==============================] - 157s 45ms/step - loss: 0.0017 - sparse_categorical_accuracy: 0.9996 - val_loss: 1.9329 - val_sparse_categorical_accuracy: 0.9884\n",
      "Epoch 75/200\n",
      "3516/3516 [==============================] - 157s 45ms/step - loss: 0.0021 - sparse_categorical_accuracy: 0.9996 - val_loss: 262.3875 - val_sparse_categorical_accuracy: 0.9890\n",
      "Epoch 76/200\n",
      "3516/3516 [==============================] - 157s 45ms/step - loss: 0.0021 - sparse_categorical_accuracy: 0.9996 - val_loss: 56.5535 - val_sparse_categorical_accuracy: 0.9883\n",
      "Epoch 77/200\n",
      "3516/3516 [==============================] - 157s 45ms/step - loss: 0.0024 - sparse_categorical_accuracy: 0.9995 - val_loss: 0.1173 - val_sparse_categorical_accuracy: 0.9894\n",
      "Epoch 78/200\n",
      "3516/3516 [==============================] - 157s 45ms/step - loss: 0.0018 - sparse_categorical_accuracy: 0.9997 - val_loss: 1.0001 - val_sparse_categorical_accuracy: 0.9886\n",
      "Epoch 79/200\n",
      "3516/3516 [==============================] - 156s 44ms/step - loss: 0.0021 - sparse_categorical_accuracy: 0.9996 - val_loss: 0.1112 - val_sparse_categorical_accuracy: 0.9882\n",
      "Epoch 80/200\n",
      "3516/3516 [==============================] - 156s 44ms/step - loss: 0.0018 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.1545 - val_sparse_categorical_accuracy: 0.9886\n",
      "Epoch 81/200\n",
      "3516/3516 [==============================] - 157s 45ms/step - loss: 0.0017 - sparse_categorical_accuracy: 0.9996 - val_loss: 6.7095 - val_sparse_categorical_accuracy: 0.9890\n",
      "Epoch 82/200\n",
      "3516/3516 [==============================] - 157s 45ms/step - loss: 0.0020 - sparse_categorical_accuracy: 0.9996 - val_loss: 0.1142 - val_sparse_categorical_accuracy: 0.9885\n",
      "Epoch 83/200\n",
      "3516/3516 [==============================] - 157s 45ms/step - loss: 0.0020 - sparse_categorical_accuracy: 0.9996 - val_loss: 0.0992 - val_sparse_categorical_accuracy: 0.9900\n",
      "Epoch 84/200\n",
      "3516/3516 [==============================] - 157s 45ms/step - loss: 0.0014 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.5133 - val_sparse_categorical_accuracy: 0.9883\n",
      "Epoch 85/200\n",
      "3516/3516 [==============================] - 157s 45ms/step - loss: 0.0017 - sparse_categorical_accuracy: 0.9996 - val_loss: 0.1100 - val_sparse_categorical_accuracy: 0.9905\n",
      "Epoch 86/200\n",
      "3516/3516 [==============================] - 157s 45ms/step - loss: 0.0021 - sparse_categorical_accuracy: 0.9996 - val_loss: 0.1754 - val_sparse_categorical_accuracy: 0.9883\n",
      "Epoch 87/200\n",
      "3516/3516 [==============================] - 157s 45ms/step - loss: 0.0015 - sparse_categorical_accuracy: 0.9997 - val_loss: 427.0164 - val_sparse_categorical_accuracy: 0.9889\n",
      "Epoch 88/200\n",
      "3516/3516 [==============================] - 157s 45ms/step - loss: 0.0016 - sparse_categorical_accuracy: 0.9997 - val_loss: 2661.8154 - val_sparse_categorical_accuracy: 0.9894\n",
      "Epoch 89/200\n",
      "3516/3516 [==============================] - 157s 45ms/step - loss: 0.0018 - sparse_categorical_accuracy: 0.9996 - val_loss: 0.1719 - val_sparse_categorical_accuracy: 0.9896\n",
      "Epoch 90/200\n",
      "3516/3516 [==============================] - 156s 44ms/step - loss: 0.0013 - sparse_categorical_accuracy: 0.9997 - val_loss: 5.8366 - val_sparse_categorical_accuracy: 0.9875\n",
      "Epoch 91/200\n",
      "3516/3516 [==============================] - 154s 44ms/step - loss: 0.0019 - sparse_categorical_accuracy: 0.9996 - val_loss: 24.3505 - val_sparse_categorical_accuracy: 0.9900\n",
      "Epoch 92/200\n",
      "3516/3516 [==============================] - 161s 46ms/step - loss: 0.0016 - sparse_categorical_accuracy: 0.9996 - val_loss: 8246.3281 - val_sparse_categorical_accuracy: 0.9890\n",
      "Epoch 93/200\n",
      "3516/3516 [==============================] - 160s 46ms/step - loss: 0.0013 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.4016 - val_sparse_categorical_accuracy: 0.9885\n",
      "Epoch 94/200\n",
      "3516/3516 [==============================] - 152s 43ms/step - loss: 0.0018 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.9143 - val_sparse_categorical_accuracy: 0.9891\n",
      "Epoch 95/200\n",
      "3516/3516 [==============================] - 155s 44ms/step - loss: 0.0018 - sparse_categorical_accuracy: 0.9997 - val_loss: 4.2574 - val_sparse_categorical_accuracy: 0.9887\n",
      "Epoch 96/200\n",
      "3516/3516 [==============================] - 161s 46ms/step - loss: 0.0018 - sparse_categorical_accuracy: 0.9997 - val_loss: 1193.6361 - val_sparse_categorical_accuracy: 0.9902\n",
      "Epoch 97/200\n",
      "3516/3516 [==============================] - 161s 46ms/step - loss: 0.0015 - sparse_categorical_accuracy: 0.9997 - val_loss: 1.3925 - val_sparse_categorical_accuracy: 0.9897\n",
      "Epoch 98/200\n",
      "3516/3516 [==============================] - 160s 45ms/step - loss: 0.0015 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.4177 - val_sparse_categorical_accuracy: 0.9879\n",
      "Epoch 99/200\n",
      "3516/3516 [==============================] - 155s 44ms/step - loss: 0.0019 - sparse_categorical_accuracy: 0.9997 - val_loss: 20762.6523 - val_sparse_categorical_accuracy: 0.9897\n",
      "Epoch 100/200\n",
      "3516/3516 [==============================] - 161s 46ms/step - loss: 0.0018 - sparse_categorical_accuracy: 0.9997 - val_loss: 1681.7190 - val_sparse_categorical_accuracy: 0.9888017 - sparse_categorical_accura\n",
      "Epoch 101/200\n",
      "3516/3516 [==============================] - 160s 46ms/step - loss: 0.0015 - sparse_categorical_accuracy: 0.9997 - val_loss: 38414.5391 - val_sparse_categorical_accuracy: 0.9889\n",
      "Epoch 102/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0015 - sparse_categorical_accuracy: 0.9997 - val_loss: 91.9181 - val_sparse_categorical_accuracy: 0.9906\n",
      "Epoch 103/200\n",
      "3516/3516 [==============================] - 161s 46ms/step - loss: 0.0017 - sparse_categorical_accuracy: 0.9997 - val_loss: 125.6030 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 104/200\n",
      "3516/3516 [==============================] - 160s 46ms/step - loss: 0.0015 - sparse_categorical_accuracy: 0.9997 - val_loss: 11142.0859 - val_sparse_categorical_accuracy: 0.9905\n",
      "Epoch 105/200\n",
      "3516/3516 [==============================] - 160s 46ms/step - loss: 0.0017 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.1405 - val_sparse_categorical_accuracy: 0.9892\n",
      "Epoch 106/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0014 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.1585 - val_sparse_categorical_accuracy: 0.9899\n",
      "Epoch 107/200\n",
      "3516/3516 [==============================] - 156s 44ms/step - loss: 0.0023 - sparse_categorical_accuracy: 0.9996 - val_loss: 0.1372 - val_sparse_categorical_accuracy: 0.9891\n",
      "Epoch 108/200\n",
      "3516/3516 [==============================] - 152s 43ms/step - loss: 0.0012 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.1450 - val_sparse_categorical_accuracy: 0.9896\n",
      "Epoch 109/200\n",
      "3516/3516 [==============================] - 152s 43ms/step - loss: 0.0015 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.1418 - val_sparse_categorical_accuracy: 0.9896\n",
      "Epoch 110/200\n",
      "3516/3516 [==============================] - 152s 43ms/step - loss: 0.0013 - sparse_categorical_accuracy: 0.9997 - val_loss: 2568.9580 - val_sparse_categorical_accuracy: 0.9893\n",
      "Epoch 111/200\n",
      "3516/3516 [==============================] - 152s 43ms/step - loss: 0.0017 - sparse_categorical_accuracy: 0.9998 - val_loss: 16227.6445 - val_sparse_categorical_accuracy: 0.9890\n",
      "Epoch 112/200\n",
      "3516/3516 [==============================] - 153s 44ms/step - loss: 0.0018 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.1478 - val_sparse_categorical_accuracy: 0.9899\n",
      "Epoch 113/200\n",
      "3516/3516 [==============================] - 157s 45ms/step - loss: 0.0012 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.1532 - val_sparse_categorical_accuracy: 0.9884\n",
      "Epoch 114/200\n",
      "3516/3516 [==============================] - 159s 45ms/step - loss: 0.0012 - sparse_categorical_accuracy: 0.9998 - val_loss: 18708.3770 - val_sparse_categorical_accuracy: 0.9882\n",
      "Epoch 115/200\n",
      "3516/3516 [==============================] - 161s 46ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9996 - val_loss: 0.1122 - val_sparse_categorical_accuracy: 0.9894\n",
      "Epoch 116/200\n",
      "3516/3516 [==============================] - 161s 46ms/step - loss: 8.8311e-04 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.1505 - val_sparse_categorical_accuracy: 0.9883\n",
      "Epoch 117/200\n",
      "3516/3516 [==============================] - 161s 46ms/step - loss: 0.0022 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.1902 - val_sparse_categorical_accuracy: 0.9894\n",
      "Epoch 118/200\n",
      "3516/3516 [==============================] - 159s 45ms/step - loss: 0.0014 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.1896 - val_sparse_categorical_accuracy: 0.9881\n",
      "Epoch 119/200\n",
      "3516/3516 [==============================] - 153s 44ms/step - loss: 0.0019 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.1404 - val_sparse_categorical_accuracy: 0.9895\n",
      "Epoch 120/200\n",
      "3516/3516 [==============================] - 153s 43ms/step - loss: 0.0015 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.3695 - val_sparse_categorical_accuracy: 0.9909 0.0016 - sparse_cat\n",
      "Epoch 121/200\n",
      "3516/3516 [==============================] - 153s 43ms/step - loss: 0.0012 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.9952 - val_sparse_categorical_accuracy: 0.9887\n",
      "Epoch 122/200\n",
      "3516/3516 [==============================] - 153s 44ms/step - loss: 0.0016 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.1448 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 123/200\n",
      "3516/3516 [==============================] - 153s 43ms/step - loss: 0.0013 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.2591 - val_sparse_categorical_accuracy: 0.9885\n",
      "Epoch 124/200\n",
      "3516/3516 [==============================] - 153s 43ms/step - loss: 0.0019 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.1552 - val_sparse_categorical_accuracy: 0.9893\n",
      "Epoch 125/200\n",
      "3516/3516 [==============================] - 155s 44ms/step - loss: 0.0011 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.2178 - val_sparse_categorical_accuracy: 0.9905\n",
      "Epoch 126/200\n",
      "3516/3516 [==============================] - 168s 48ms/step - loss: 0.0014 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.2516 - val_sparse_categorical_accuracy: 0.989317 - sparse_categorical_ac - ETA:  - ETA: 1:12 - loss: - ETA: 1:09 - loss: 0.0015 - sp - ETA: 1:08 - loss: 0.001 - ETA: 1:05 - loss: 0.0014 - sparse_categorical_accuracy: - ETA: 1:05 - loss: 0.0014 - sparse_categorical_accuracy: 0 - ETA: 1:04 - loss:  - ETA: 18s - loss: 0.0014 - sparse_ca - ETA: 17s - loss: 0.0014 - spars - ETA: 7s - loss: 0.0014 - sparse_ca - ETA: 5s - loss: 0.0014 - sparse_categor - ETA: 3s - loss: 0.0014 - sparse_categorical_a - ETA: 2s - loss: 0.0014 -\n",
      "Epoch 127/200\n",
      "3516/3516 [==============================] - 171s 49ms/step - loss: 0.0016 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.1459 - val_sparse_categorical_accuracy: 0.98991.00 - ETA: 3:10 - loss: 2.1113e-06 - sparse_cat - ETA: 2:49 - loss: 4.0512e-04 - sparse_categorical_accuracy:  - ETA: 2:51 - loss: 0.0014 - sparse_categorical_accuracy: 0.9 - ETA: 2:53 - loss: 0.0013 - sparse_categorical_accura - ETA: 2:54 - loss: 0.0011 - sparse_categoric - - ETA: 2:46 - loss: 0.0015 - sparse_categorical_accuracy: - ETA: 2:47 - loss: 0.0015 - sparse_categorical_accuracy: - ETA: 2:46 - loss: 0.0018 - sparse_categoric - ETA: 2:50 - loss: 0.0018 - sparse_categorical_accurac - ETA: 2:49 - loss: 0.0018 - sparse_categori - ETA: 2:51 - loss: 0.0018 - sparse_ - ETA: 2:57 - loss: 0.0017 - sparse_categori - ETA: 2:56 - loss: 0.0016 - sparse_categorical_accuracy: 0. - ET - ETA: 2:45 - loss: 0.0020 - sparse_categorica - ETA: 2:42 -  - ETA: 2:35 - loss: 0.0016 - spar - ETA: 2: - ETA: 2:24 - loss: 0.0014 - sparse_categorical_accuracy: 0. - ETA: 2:24 - ETA: 2:18 - loss: 0.0013 - sparse_categorical_accuracy: 0.999 - ETA: 2:18 - loss: 0.0013 - sparse_categorical_accuracy: 0 - ETA: 2:17 - loss: 0.0013 - sparse_categorical_acc - ETA: 2:16 - loss: 0.0013 - s - ETA: 2:05 - loss: 0.0013 - sparse_categorical_accuracy - ETA: 2:04  - ETA: 2:00 - loss: 0.0012 - sparse_categori - ETA: 1:58 - loss: 0.0012 - sparse_categorical_accura - ETA: 1:57 - loss: 0.0012 - sparse_cat - ETA: - ETA: 1:49 - loss - ETA: 1:45 - loss: 0.0013 - sparse_cate - ETA: 9s - loss: 0.0017 - sparse_categorical_accuracy: 0.999 - ETA: 9s - loss: 0.0017 - sparse_categorical_accu - ETA: 8s  - ETA: 3s - loss: 0.0017 - sparse_categorical_accu - ETA: 1s - loss: 0.0017 - sparse_categor\n",
      "Epoch 128/200\n",
      "3516/3516 [==============================] - 162s 46ms/step - loss: 0.0013 - sparse_categorical_accuracy: 0.9998 - val_loss: 23.1394 - val_sparse_categorical_accuracy: 0.9878: 2:36 - loss: 0.0047 - sparse_categorical_accuracy: - ETA: 2:29 - loss: 0.0016 - sparse_categorical_accura - ETA: 2:28 - loss: 0.0015 - sparse_ca - ETA: 2:26 - loss: 0.0011 - sparse_categorical_a - ETA: 2:24 - loss: 0.0011 - s - ETA: 2:21 - loss: 0.0016 - sparse_categorical_accurac - ETA: 2:20 - loss: 0.0015 - sparse_categorical_accu - ETA: 2:19 - loss: 0.0014 - sparse_categorical_accuracy: 0.999 - ETA: 2:19 - - ETA: 2:15 - loss: 0.0013 - sparse_categorical_accu - ETA: 2:14 - loss: 0.0013 - sparse_categorical_accurac - ETA: 2:13 - loss: 0.0013 - sparse_categorica - ETA: 2:08 - loss: 0.0011 - sp - ETA: - ETA: 1:56 - loss: 0.0011 - sparse_ca - ETA: 1:55 - loss:  - ETA: 1:52 - loss: 0.0010 - sparse_categorical_a - ETA: 1:51 - loss: 0.0010 - sparse_categorical_acc - ETA: 1:50 - loss: 0.0010 - sparse_categorical_accuracy: 0. - ETA: 1:50 - loss: 0.0010 - sparse_categorical_accura - ETA: 1:49 - loss: 0.0010 - sparse_categorical_accuracy:  - ETA: 1:49 - loss: 0.0010 - sparse_ca - ETA: 1:4 - ETA: 1:43 - ETA: 36s - loss: 0.0 - ETA: 8s - loss: 0.0013 - sparse_categor - ETA: 7s - loss: 0.0013 - sparse_catego - ETA: 5s - loss: 0.0013 - sparse_categorical_accur - ETA: 5s - loss: - ETA: 1s - loss: 0.0014 - sparse_categorical_accuracy:  - ETA: 1s - loss: 0.0014 - sparse_categorical_\n",
      "Epoch 129/200\n",
      "3516/3516 [==============================] - 153s 44ms/step - loss: 0.0019 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.1298 - val_sparse_categorical_accuracy: 0.9892\n",
      "Epoch 130/200\n",
      "3516/3516 [==============================] - 155s 44ms/step - loss: 0.0014 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.1404 - val_sparse_categorical_accuracy: 0.99025s - loss - ETA: 2s - loss: 0.0013 - sparse_categorical - ETA: 0s - loss: 0.0014 - sparse_categorical_accuracy: 0.999 - ETA: 0s - loss: 0.0014 - sparse_categorical_accuracy: \n",
      "Epoch 131/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0015 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.1437 - val_sparse_categorical_accuracy: 0.9881oss: 7.4389e-04 - sparse_ca - ETA: 2:34 - loss: 5.8588e-04 - sparse_categorical_accuracy: 0. - ETA: 2:33 - loss: 5.6035e-04 - sparse_categorical_accuracy: 0.9 - ETA: 2:33 - loss: 5.7149e-04 - sparse_categorical_accur - ETA: 2:31 - loss: 5.1799e-04 - sparse_c - ETA: 2:27 - loss: 5.1211e-04 - sparse_categor - ETA: 2:26 - loss: 4.5246e-04 - sparse_categorical_accu - ETA: 2:24 - loss: 4.2048e-04 - sparse_categorical - ETA: 2:22 - loss: 3. - ETA: 2:17 - loss: 6.8295e-04 - s - ETA: 2:14 - loss: 7.3166e-04 - sparse_categorical_a - ETA: 2:13 - loss: 7.8831e-04 - sparse_categorical_accuracy: 0.9 - ETA: 2:12 - loss: 8.4572e-04 - sparse_categorical - ETA:  - ETA: 15s - loss: 0.0013 - spars - ETA: 13s - loss: 0.0014 - sparse_categorical_accura - ETA: 13s - loss: 0.00 - ETA: 11s  - ETA: 8s - loss: 0.0014 - sparse_categorical_accuracy: 0.999 - E - ETA: 3s - loss: 0 - ETA: 0s - loss: 0.0015 - sparse_categorical_accuracy: 0.999 - ETA: 0s - loss: 0.0015 - sparse_categorical_accuracy:\n",
      "Epoch 132/200\n",
      "3516/3516 [==============================] - 163s 46ms/step - loss: 0.0020 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.1157 - val_sparse_categorical_accuracy: 0.9888TA: 2:55 - ETA: 2:37 - loss: 0.0052 - sparse_categorical_ac - ETA: 2:35 - loss: 0.0046 - sparse_categorical_accuracy: 0.9 - ETA: 2:34 - loss: 0.0045 - sparse_categorical_accu - ETA:  - ETA: 2:30 - loss - ETA: 2:25 - loss: 0.0022 - ETA: 2:24 - loss: 0.002 - ETA: 2:22 - loss: 0.0018 - sparse_categorical_accuracy: - ET - ETA: 2:14 - loss: 0.0018 - sparse_ca - ETA: 2:11 - loss: 0.0017 - spar - ETA: 2:08 - loss: 0.0018 - sparse_categorical_accu - ETA: 2:07 - loss: 0.0017 - sparse_categorical_accurac - ETA: 2:06 - loss: 0.0017 - sparse_categorical_accur - ETA: 2:05 - loss: 0.0017 - sparse_categorical_accuracy: 0. - ETA: 2:05 - loss: 0.0017 - sparse_categorical_accura - ETA: 2:04 - loss: 0.0 - ETA: 2:00 - loss: 0 - ETA: 1:5 - ETA: 1:48 - loss: 0.0018 - sparse_categorical_accura - ETA: 1:48 - loss: 0.0018 - sparse_categorical_ - ETA: 1:47 - loss: 0.0018 - sparse_categorical_accuracy: 0. - ETA: 1:46 - loss: 0.0018 - sparse_categorical_a - ETA: 1:45 - loss: 0.0018 - sparse - ETA: 1:44 - loss: 0.0017 - sparse_categorical_a - ETA: 1:42 - loss: 0.0017 - sparse_categorical_accurac - ETA: 1:42 - loss: 0.0017 - sparse_categorical_accu - ETA: 1:41 - loss: 0.0016 - sparse_categorical_accuracy: 0. - ETA: 1:41 - loss: 0.0016 - sparse_categorical_accuracy: 0.999 - ETA: 1:41 - loss: 0.0016 - sparse_categorical_a - ETA: 1:39 - loss: 0.0016 - sparse_categorical_accuracy: 0 - ETA: 1:39 - loss: 0.0016 - spa - ETA: 1:36 - loss: 0.0016 - sparse_categorical_accuracy: 0.99 - ETA: 1:36 - loss: 0.0016 - sparse_cate - ETA: 1:34 - loss: 0.0015 - sparse_categorical_accuracy: 0.99 - ETA: 1:34 - loss - ETA: 1:30 - loss: 0.0015 - sparse_categorical_a - ETA: 1:29 - loss: 0.0014 - sparse_categorical_accuracy: 0.99 - ETA: 1:29 - loss: 0.0014 - sparse_categori - ETA: 1:27 - loss: 0.0014 - sparse_categorical_accurac - ETA: 1:26 - loss: 0.0014 - sparse_categoric - ETA: 1:24 - loss: 0.0014 - sparse_categorical_accuracy: 0. - ETA: 1:24 - loss: 0.0014 - sparse_categorical_accu - ETA: 1:23 - loss: 0.0014 - - ETA: 1:19 - loss: 0.0013 - sparse_categorical_accuracy:  - ETA: 1:19 - loss - ETA: 1:14 - loss: 0.0015 - sparse_cate - ETA: 1:12 - loss: 0.0015 - sparse_categorical_accura - ETA: 1:11 - loss: 0.0018 - sparse_categorical_accuracy - ETA: 1:10 - loss: 0.0018 - sparse_categorical_ac - ETA: 1:09 - loss: 0.0018 - sparse_categorical_accuracy:  - ETA: 1:08 - loss: 0.0018 - sparse_categorical - ETA: 1:07 - loss: 0.0018 - sparse_categorical_accuracy:  - ETA: 1:06 - loss: 0.0018 - sparse_categorical_accuracy - ETA: 1:05 - loss: 0.0018 - sparse_categorica - ETA: 1:04 - loss: 0.0018 - sparse_categorical_accur - ETA: 1:03 - loss: 0.0018 - sparse_categorical_accuracy:  - ETA: 1:02 - loss: 0.0018 - sparse_cat - ETA: 1:00 - loss: 0.0019 - sparse_categorical_accuracy: 0.999 - ETA: 59s - loss: 0.0019 - sparse_cat - ETA: 58s - loss: 0.0019 - sparse_categorical_accuracy - ETA: 58s - loss: 0.0019 - - ETA: 53s - loss: 0.0019 - spa - ETA: 52s - loss: 0.0019 - sparse_categorica - ETA: 51s - loss: 0.0019 - spars - ETA: 37s - loss: 0.0021 - sparse_categorical_accuracy - ETA: 37s - loss: 0.0021 - sparse_categorical_accuracy: 0.99 - ETA: 37s - loss: 0.0021 - sparse_cate - ETA: 36s - loss: 0.0021 - sparse_ - ETA: 34s - loss: 0.0021 - spars - ETA: 33 - ETA: 28s - loss: 0.0020 - - ETA: 26s - loss: 0.0020 - sparse_categori - ETA: 25s - loss: 0.0020 - sparse_categorical_ - ETA: 24s - loss: 0.0020 - sparse_categori - ETA: 20s  - ETA: 18s - loss: 0. - ETA: 16s  - ETA: 11s - loss: 0.0019 - spar - ETA: 9s - loss: 0.0019 - sparse_categorical_a - ETA: 8s - loss: 0.0018 - sparse_c - ETA: 5s - loss: 0.0018 - sparse_categorical_accuracy:  - ETA: 5s - loss: 0.0018 - sparse_categorical_accuracy - ETA: 4s - loss - ETA: 0s - loss: 0.0020 - sparse_categorical_accuracy: 0.9\n",
      "Epoch 133/200\n",
      "3516/3516 [==============================] - 160s 45ms/step - loss: 0.0013 - sparse_categorical_accuracy: 0.9998 - val_loss: 13014.4092 - val_sparse_categorical_accuracy: 0.9897 2:37 - loss: 3.6141e-04 - sparse_ - ETA: 2:34 - loss: 0.0011 - sparse_categorical_accuracy: 0.999 - ETA: 2:34 - - ETA: 2:30 - loss: 0.0012 - sparse_categorical_accur - ETA: 2:29 - loss: 0.0011 - sparse_categorical_accuracy - ETA: 2:28 - loss: 0.0011 - sparse_categorical_accuracy: 0. - ETA: 2:28 - loss: 0.0011 - sparse - ETA: 2:24 - loss: 0.0011 - sparse_categorica - ETA: 2:23 - loss: 0.0010 - sparse_categorical_accuracy:  - ETA: 2:23 - loss: 9.9658e-04 - sparse_categorical_accuracy:  - ETA: 2:23 - loss: 9.6560e-04 - sparse_categorical_accuracy: 0.99 - ETA: 2:23 - loss: 9.5516e-04 - sparse_categorical_accura - ETA: 2:22 - loss: 9.1060e-04 - spars - ETA: 2:19 - loss: 7.9085e-04 - sparse - ETA: 2:16 - loss: - ETA: 2:12 - loss: 6.9316e-04 - - ETA: 2:08 - loss: 0.0011 - sparse_categorical_accuracy: 0.999 - ETA: 2:08 - loss: 0.0011 - sparse_ca - ETA: 2:06 - loss: 0.0011 - sparse_categorical_accurac - ETA: 2:05 - loss: 0.0011 - sparse_categorical_acc - ETA: 2:04 - loss: 0.0010 - sparse_categori - ETA: 2:02 - loss: 9.8919e-04 - sparse_categorical_accuracy - ETA: 2:02 - loss: 9.7024e-04 - sparse_categorica - ETA: 2:00 - loss: 9.8793e-04 - sparse_categorical_ - ETA: 1:59 - loss: 0.0010 - spar - ETA: 1:56 - loss: 9.6139e-04 - sparse_categorical_ac - ETA: 1:55 - loss: 9.3500e-04 - sparse_categorical_accurac - ETA: 1:54 - loss: 9.1870e-04 - sparse - ETA: 1:51 - loss: 8.7671e-04 - sparse_categorical_accuracy: 0.999 - ETA: 1:51 - loss: 8.7505e-04 - sparse_categorical_accu - ETA: 1:50 - loss: 8.7033e-04 - sparse_categorical_accuracy: 0 - ETA: 1:50 - loss: 8.6268e-04 - sparse_categor - ETA: 1:48 - loss: 9.0700e-04 - sparse_c - ETA: 1:45 - loss: 8.7273e-04 - sparse_ca - ETA: 1:43 - loss: 0.0012 - sparse_categorical_accuracy: 0 - ETA: 1:42 - loss: 0.0012 - sparse_categorical_accuracy: 0.999 - ETA: 1:42 - loss: 0.0012 - sparse_categorical_accur - ETA: 1:41 - loss: 0.0012 - sparse_categorical_accuracy: 0.999 - ETA: 1:41 - loss: 0.0012 - spars - ETA: 1:39 - loss: - ETA: 1:35  - ETA: 1:30 - loss: 0.0013 - sparse_categorical_accuracy: - ETA: 1:29 - loss: 0.0013 - sparse_categorical_accuracy: 0 - ETA: 1:29 - loss: 0.0013 - sparse_categ - ETA: 1:27 - loss: 0.0013 - spa - ETA: 1:24 - loss: 0.0013 - sparse_categoric - ETA: 1:22 - loss: 0 - ETA: 1:18 - loss: 0.0014 - sparse_categorical_accur - ETA: 1:17 - loss: 0.0014 - sparse_categorica - ETA: 1:15 - loss: 0.0015 - sparse_categorical_accuracy: 0 - ETA: 1:15 - loss: 0.0015 - sparse_categorical_accuracy: 0. - ETA: 1:15 - loss: 0.0015 - sparse_categorical_accuracy: 0.99 - ETA: 1:14 - loss: 0.0015 - spar - ETA: 1:06 - loss: 0.0014 - sparse_categorical_ac - ETA: 1:05 - loss: 0.0014 - sparse_categorical_accura - ETA: 1:04 - loss: 0.0014 - sparse_categorical_accuracy: 0.999 - ETA: 1:04 - loss: 0.0014 - sparse_categorical_accuracy: 0.999 - ETA: 1:03 - loss: 0.0014 - sparse_categorical_accuracy - ETA: 1:03 - loss: 0.0014 - sparse_cat - ETA: 1:01 - loss: 0.0014 - spa - ETA: 59s - lo - ETA: 51s - loss: 0.0013 - sparse_categori - ETA: 50s - loss: 0.0013 - sparse_categorica - ETA: 49s - loss: 0.0013 - sparse_categorica - ETA: 48s - loss: 0.0013 - sparse_categorical_accuracy - ETA: 48s - loss: 0. - ETA: 43s - loss: 0.0013 - - ETA: 41 - ETA: 27s - loss: 0.0013 - spars - ETA: 26s - loss: 0.0013 - s - ETA: 24s - loss: 0.0013 - sparse_ - ETA: 20s - loss - ETA: 18s - loss: 0.0012 - sparse_categorical_accuracy: 0. - E - ETA: 12s - loss: 0.0012 - sparse_categorical_accuracy:  - ET - ETA: 9s - loss: 0.0012 - sparse - ETA: 7s - loss: 0.00 - ETA: 3s - loss: 0.0012 - sparse_categorical_ - ETA: 2s - loss: 0.0012 - sparse_categorical_ac - ETA: 0s - loss: 0.0012 - sparse_categorical_accuracy: 0.999 - ETA: 0s - loss: 0.0012 - sparse_categorical_accur\n",
      "Epoch 134/200\n",
      "3516/3516 [==============================] - 155s 44ms/step - loss: 0.0016 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.1818 - val_sparse_categorical_accuracy: 0.9890 ETA: 2:37 - loss: 9.6090e-05 - sparse_categorical_ac - ETA: 2:36 - loss: 1.5192e-04 - sparse_categorical_accuracy: 1.000 - ETA: 2:36 - loss: 1.6915e-04 - sparse_c - ETA: 2:34 - loss: 1.8677e-04 - sparse_categorical_accuracy: 1.000 - ETA: 2:33 - lo\n",
      "Epoch 135/200\n",
      "3516/3516 [==============================] - 152s 43ms/step - loss: 0.0018 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.1653 - val_sparse_categorical_accuracy: 0.9886018 - sparse_categorical_accuracy: 0.9 - ETA: 7s - loss: 0.001 - ETA: 4 - ETA: 0s - loss: 0.0018 - sparse_categorical_accuracy: 0.\n",
      "Epoch 136/200\n",
      "3516/3516 [==============================] - 150s 43ms/step - loss: 0.0017 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.2971 - val_sparse_categorical_accuracy: 0.9890\n",
      "Epoch 137/200\n",
      "3516/3516 [==============================] - 151s 43ms/step - loss: 0.0011 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.3495 - val_sparse_categorical_accuracy: 0.9901\n",
      "Epoch 138/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0024 - sparse_categorical_accuracy: 0.9996 - val_loss: 0.1263 - val_sparse_categorical_accuracy: 0.9898: 2:10 - loss: 0.0012 - sparse_categorical_acc - - ETA: 2:12 - loss: 9.5281e-04 - sparse_categorical_accu - ETA: 2:12 - loss: 9.2397e-04 - sparse_categorical_accuracy: 0 - ETA: 2:11 - loss: 9.0832e-04 - sparse_categor - ETA: 2:09 - loss: 8.4944e-04 - sparse_categorical_ac  - ETA: 1:58 - loss: 0.00 - ETA: 16s - loss: - ETA: 7 - ETA: 2s - loss: 0.0024 - sparse_categoric - ETA: 1s - loss: 0.0024 - sparse_categorical\n",
      "Epoch 139/200\n",
      "3516/3516 [==============================] - 156s 44ms/step - loss: 9.9943e-04 - sparse_categorical_accuracy: 0.9998 - val_loss: 17.7183 - val_sparse_categorical_accuracy: 0.9887\n",
      "Epoch 140/200\n",
      "3516/3516 [==============================] - 153s 44ms/step - loss: 0.0016 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.7339 - val_sparse_categorical_accuracy: 0.9908\n",
      "Epoch 141/200\n",
      "3516/3516 [==============================] - 153s 44ms/step - loss: 0.0017 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.1457 - val_sparse_categorical_accuracy: 0.9877\n",
      "Epoch 142/200\n",
      "3516/3516 [==============================] - 150s 43ms/step - loss: 0.0012 - sparse_categorical_accuracy: 0.9998 - val_loss: 17.4736 - val_sparse_categorical_accuracy: 0.9894\n",
      "Epoch 143/200\n",
      "3516/3516 [==============================] - 151s 43ms/step - loss: 0.0018 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.1823 - val_sparse_categorical_accuracy: 0.9889\n",
      "Epoch 144/200\n",
      "3516/3516 [==============================] - 155s 44ms/step - loss: 0.0017 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.1732 - val_sparse_categorical_accuracy: 0.9900\n",
      "Epoch 145/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0015 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.1731 - val_sparse_categorical_accuracy: 0.9890- loss: 5.1745e-04 - sparse_categorical_accuracy: 0.9 - ETA: 2:03 - loss: 5.1742e-04 - sparse_categorical_accuracy: 0.999 - ETA: 2: - ETA: 1:59 - loss: 4.5254e-04  - ETA: 1:56 - loss: 4.1586e-04 - sparse_categoric - ETA: 1:55 - loss: 4.0072e-04 - sparse_categorical_accuracy: 0.99 - ETA: 1:55 - loss: 3.9943e-04 - sparse - ETA: 1:52  - ETA: 1:49 - loss: 3.4477e-04 - sparse_categorical_accuracy: 0.99 - ETA: 1:48 - loss: 3.4353e-04 - sparse_categorica - ETA: 1:47 - loss: 4.0954e-04 - sparse_categorical_accuracy: 0.999 - ETA: 1:47 - loss: 4.1057e-04 - spa - ETA: 1:39 - loss: 6.1710e-04 -  - ETA: 6s - loss: 0.0015 - s - ETA: 3s - loss: 0.0014 - sparse_categorical_accuracy: 0.9 - ETA: 2s - loss: 0.0014 - sparse_categorical_acc - ETA: 1s - loss: 0.0014 - sparse_catego\n",
      "Epoch 146/200\n",
      "3516/3516 [==============================] - 156s 44ms/step - loss: 0.0013 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.1135 - val_sparse_categorical_accuracy: 0.9908loss: 0.0011 - sparse_categorical_accuracy: 0.9 - ETA: 2:37 - loss: 0.0013 - sparse_categorical_accuracy: 0.999 - ETA: 2:37 - loss: 0.0013 - sparse_categorical_accura - ETA: 2:38 - loss: 0.0010 - sparse_categorical_accuracy:  - ETA: 2:37 - loss: 9.1007e-04 - sparse_categorica - ETA: 2:35 - loss: 8.8965e-04 - sparse_categorical_accur - ETA: 2:35 - loss: 7.8074e-04 - sparse_ca - E\n",
      "Epoch 147/200\n",
      "3516/3516 [==============================] - 154s 44ms/step - loss: 0.0012 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.1773 - val_sparse_categorical_accuracy: 0.9896\n",
      "Epoch 148/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0020 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.1487 - val_sparse_categorical_accuracy: 0.9903- loss - ETA: 1s - loss: 0.0020 - sparse_categorical_accuracy: 0.9 - ETA: 1s - loss: 0.0020 - sparse_categ\n",
      "Epoch 149/200\n",
      "3516/3516 [==============================] - 162s 46ms/step - loss: 0.0016 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.1247 - val_sparse_categorical_accuracy: 0.9901\n",
      "Epoch 150/200\n",
      "3516/3516 [==============================] - 154s 44ms/step - loss: 0.0010 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.1437 - val_sparse_categorical_accuracy: 0.9894\n",
      "Epoch 151/200\n",
      "3516/3516 [==============================] - 157s 45ms/step - loss: 0.0018 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.1339 - val_sparse_categorical_accuracy: 0.9895\n",
      "Epoch 152/200\n",
      "3516/3516 [==============================] - 156s 44ms/step - loss: 8.8194e-04 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.1687 - val_sparse_categorical_accuracy: 0.9894\n",
      "Epoch 153/200\n",
      "3516/3516 [==============================] - 160s 45ms/step - loss: 0.0021 - sparse_categorical_accuracy: 0.9997 - val_loss: 1.3412 - val_sparse_categorical_accuracy: 0.9895 0.0020 - sparse_categor - ETA: 2:05 - loss: 0.0019 -  - ETA: 1:58 - loss: 0.0016 - sparse_categorical_accur - ETA: 1:57 - loss: 0.0016 - sparse_categorical - ETA: 1:56 - loss: 0.0015 -  - ETA: 1:53 - loss: 0.0015 - sparse_categorical_accuracy - ETA: 1:52 - loss - ETA:  - ETA:  - ETA: 1:35 - loss: 0.0014 - sparse_categorical_accu - ETA: 1:34 - loss: 0.0014 - sparse_categorical_accuracy:  - ETA: 1:33 - loss: 0.0013 - sparse_categorical_accuracy:  - ETA: 1:33 - loss: 0.0013 - sparse_categorical_accuracy: 0.999 - ETA: 1:33 - loss: 0.0013 - sparse_categorical_accur - ETA: 1:32 - loss: 0.0013 - sparse_categorical_accuracy: 0.9 - ETA: 1:31 - loss: 0.0013 - sparse_ca - ETA: 1:29 - loss: 0.0015 - spars - ETA: 1:27 - loss: 0.0015 - sparse_categorical_accuracy: - ETA: 1:26 - loss: 0.0014 - sparse_categorica - ETA: 1:25 - loss: 0.0014 - sparse_categorical_accuracy: 0 - ETA: 1 - ETA: 1:19 - loss: 0.0015 - sparse_categorical_accuracy: 0.9 - ETA: 1:19 - loss: 0.0015 - sparse_categorical_accuracy: 0.999 - ETA: 1:19 - loss: 0.0015 - sp - ETA: 29s - loss: 0.0016 - sparse_ca - ETA: 28s - loss: 0.0016 - s - ETA: 24s - loss: 0.0016 - sparse_categorical_ac - ETA: 23s - loss: 0.0016 - spars - ETA: 13s - loss: 0.0016 -  - ETA: 8s - loss: 0. - ETA: 5s - loss - ETA: 0s - loss: 0.0021 - sparse_categorical_acc\n",
      "Epoch 154/200\n",
      "3516/3516 [==============================] - 157s 45ms/step - loss: 0.0015 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.1039 - val_sparse_categorical_accuracy: 0.9902 0.0015 - sparse_categorical_accuracy - ETA: 41s - loss: 0.0015 - sparse_categorical_accuracy: 0. - ETA: 41s - loss: 0.0015 - sparse_categorical_accuracy: 0. - ETA: 41s - loss: 0.0015 - sparse_cate - ETA: 40s - loss: 0.0016 - sparse_categorical_accuracy: 0. - ETA: 37s - loss: 0.0016 - sparse_categorical_accuracy - ETA: 37s - loss: 0.0016 - s - ETA: 35s - loss: 0.0016 - sparse_categorical_accuracy: 0. - ETA: 35s -  - ETA: 33s - loss: 0.0016 - sparse_categorical_accuracy - E - ETA: 28s - loss: 0.0015 - sparse_ca - ETA: 0s - loss: 0.0015 - sparse_categorical_accuracy: 0.\n",
      "Epoch 155/200\n",
      "3516/3516 [==============================] - 161s 46ms/step - loss: 0.0016 - sparse_categorical_accuracy: 0.9998 - val_loss: 42.0488 - val_sparse_categorical_accuracy: 0.9895- sparse_categorical_accur - ETA: 2:07 - loss: 5.0626e-04 - sparse_catego - ETA: 2:06 - loss: 7. - ETA: 2:02 - los - ETA: 1:57 - loss: 9.7329e-04  - ETA: 1:54 - loss: 9.6729e- - ETA: 1:44 - loss: 0.0011 - sparse_categorical_acc - ETA: 1:43 - loss: 0.0011 - sparse_ca - ETA: 1:41 - loss: 0.0012 - sparse_categorical_a - ETA: 1:39 - loss: 0.0012 - spars - ETA: 1:25 - loss: 0.0017 - sparse_categorical_accura - ETA: 1:24 - loss: 0.0017 - sparse_categori - ETA: 1:23 - loss: 0.0016 - sparse_categorical_accuracy:  - ETA: 1:22 - loss: 0.0016 - sparse_cat - ETA: 1:21 - loss: 0.0016 - sparse_categorical_accuracy: 0. - ETA: 1:20 - loss: 0.0016 - sparse_ - ETA: 1:12 - loss: 0.0015 - sparse - ETA: 44s - loss: 0.0016 - sparse_categorica - ETA: 43s - loss:  - ETA: 41s - loss: 0.0016 - - ETA: 40s - loss: 0.0016 - sparse_categorical_accu - ETA: 37s - loss: 0.0016 - sparse_ca - ETA: 36s - loss: 0.0016 - sparse_categorical_accuracy - ETA: 35s - loss: 0.00 - ETA: 34s - loss:  - ETA: 32s - loss: 0.0015 - sparse_categorical_accura - ETA: 31s  - ETA: 29s - loss:  - ETA: 24s - loss: 0.0015 - spar - ETA: 7s - loss: 0.0017 - sparse_categorical_ - ETA: 6s - loss: 0.0016 - sparse_categorical_accur\n",
      "Epoch 156/200\n",
      "3516/3516 [==============================] - 156s 44ms/step - loss: 0.0016 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.1762 - val_sparse_categorical_accuracy: 0.9898- loss: \n",
      "Epoch 157/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0011 - sparse_categorical_accuracy: 0.9998 - val_loss: 5.6772 - val_sparse_categorical_accuracy: 0.9901\n",
      "Epoch 158/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0017 - sparse_categorical_accuracy: 0.9997 - val_loss: 2004.5176 - val_sparse_categorical_accuracy: 0.9903 ETA - ETA:  - ETA: 6s - loss: 0.0017 - sparse_categ - ETA: 4s\n",
      "Epoch 159/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0019 - sparse_categorical_accuracy: 0.9998 - val_loss: 15290.8945 - val_sparse_categorical_accuracy: 0.9894\n",
      "Epoch 160/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 5.3244e-04 - sparse_categorical_accuracy: 0.9999 - val_loss: 8920.5752 - val_sparse_categorical_accuracy: 0.9897 - loss: 6.4146e-05 - sparse_categorical_accuracy:  - ETA: 2:35 - loss: 5.3968e-05 - sparse_categoric - ET - ETA: 2:28 - loss: 1.5035e-04 - sparse_categorical_accura - ETA:  - ETA: 2:15 - loss: 2.0020e-04 - sparse_categor - ETA: 2:13 - lo - ETA: 0s - loss: 5.3537e-04 - sparse_categorical_accu\n",
      "Epoch 161/200\n",
      "3516/3516 [==============================] - 160s 45ms/step - loss: 0.0014 - sparse_categorical_accuracy: 0.9997 - val_loss: 4918.4126 - val_sparse_categorical_accuracy: 0.9903.0013 - sparse_catego - ETA: 16s - loss: 0.0014 - sparse_categorical_accuracy: 0. - ETA: 15s - loss: 0.0014 - sparse_ - ETA: 14s - ETA: 4s - loss: 0.0014 - sparse_categorical_accuracy: - ETA: 4s - loss: 0.0014 - sparse_categorical_accu - ETA: 3s - loss: 0.0014 - sparse_categorical_accuracy:  - ETA: 2s - loss: 0.0014 - sparse_categorical_accuracy: 0.999 - ETA: 2s - loss: 0.0014 - spar\n",
      "Epoch 162/200\n",
      "3516/3516 [==============================] - 151s 43ms/step - loss: 9.3921e-04 - sparse_categorical_accuracy: 0.9998 - val_loss: 6.1484 - val_sparse_categorical_accuracy: 0.9898\n",
      "Epoch 163/200\n",
      "3516/3516 [==============================] - 163s 46ms/step - loss: 0.0015 - sparse_categorical_accuracy: 0.9997 - val_loss: 869.4488 - val_sparse_categorical_accuracy: 0.9899 loss: 0.0031 - sparse_categori - ETA: 2:05 - loss: 0.0030 - sparse_ca - ETA: 2:03 - loss: - ETA: 45s - loss: 0.0014 - sparse_catego - ETA:  - ETA: 39s - loss: 0.0016 - - ETA: 8s - loss:  - ETA: 5s - loss: 0.0016 - sparse_categorical_accurac - ETA: 4s - loss: 0.0016 - sparse_categorical_ac - ETA: 3s - loss: 0.0016 \n",
      "Epoch 164/200\n",
      "3516/3516 [==============================] - 162s 46ms/step - loss: 0.0021 - sparse_categorical_accuracy: 0.9998 - val_loss: 6.7427 - val_sparse_categorical_accuracy: 0.98960.9 - ETA: 2:31 - loss: 7.2897e-04 - sp - ETA: 2:27 - loss: 5.5942e-04 - sparse_categor - ETA: 2:27 - loss: 4.9638e-04 - sparse_categorical_accurac  - ETA: 2:19 - loss: 0.0010 - sparse_categorical_accurac - ETA: 2:18 - loss: 9.9702e-04 - sparse_categorical_accuracy: 0.999 - ETA:  - ETA: 2:13 - - ETA: 1:51 - loss: 0.0014 - sparse_categor - ETA: 1:49 - loss: 0.0019 - sparse_categor - ET - ETA: 1:43 - loss: 0.0018 - sparse_categorical_accuracy: - ETA: 1:42 - loss: 0.0018 - sparse_categorical_accur - ETA: 1:41 - loss: 0.0018 - sparse_categor - ETA:  - ETA: 1:35 - los - ETA: - ETA: 54s - loss: 0.0017 - sparse_categorical_accuracy: 0.99 - ETA: 54s - loss: 0.0017 - sparse_ - ETA: 52s - loss: 0.0017 - sparse_categorical_ac - ETA: 52s - loss: 0.0017 - sparse_categorical_accuracy - ETA: 51s - loss: 0 - ETA: 0s - loss: 0.0021 - sparse_categorical_accuracy: 0\n",
      "Epoch 165/200\n",
      "3516/3516 [==============================] - 164s 47ms/step - loss: 0.0013 - sparse_categorical_accuracy: 0.9998 - val_loss: 544.3418 - val_sparse_categorical_accuracy: 0.9891ETA: 1:31 - loss: 0.0013 - sparse_ca - ETA: 1:29 - loss: 0  - ETA: 15s -  - ETA: 1s - loss: 0.0013 - sparse_categorical_\n",
      "Epoch 166/200\n",
      "3516/3516 [==============================] - 160s 46ms/step - loss: 0.0020 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.2871 - val_sparse_categorical_accuracy: 0.9888TA: 1:38 - loss: 0.0013 - sparse_categorical_ - ETA: 1:37 - loss: 0.0 - ETA: 1:24 - los - ETA: 1:20 - loss: 0.0019 - sparse_categorical_acc - ETA: 1:19 - loss: 0.0019 - sparse_categorical_a - ETA: 1:17 - loss: 0.0019 - sparse_categorical_accuracy: - ETA: 1:11 - loss: 0.0018 - spars - ETA: 1:09 - loss: 0.0017 - sparse_categorical - ETA: 1:07 - loss: 0.0017 - sparse_categorical_accuracy - ETA - ETA: 46s - loss: 0.0015 - sparse_categorical_accura - - ETA: 43s - loss: 0.00 - ETA - ETA: 22s - loss:  - ETA: 20s - loss: 0.0017 - s - ETA: 19s  - ETA: 17s  - ETA: 14s  - ETA: 12s - loss: 0.0016 - sparse_categorical_accuracy:  - ETA: 3s - loss: 0.0020 - sparse_c - ETA: 1s - loss: 0.0020 - sparse_categorical_accu\n",
      "Epoch 167/200\n",
      "3516/3516 [==============================] - 161s 46ms/step - loss: 0.0015 - sparse_categorical_accuracy: 0.9998 - val_loss: 4202.4502 - val_sparse_categorical_accuracy: 0.9892TA: 2:37 - loss: 9.7847e-04 - sparse_catego - ETA: 2:35 - loss: 0.0024 - sparse_categorical_acc  - ETA: 2:28 - loss: 0.0019 - spar - ETA: 2:25 - loss: 0.0016 - sparse_categorical_accuracy: 0. - ETA: 2:25 -  - ETA: 2:21 - loss: 0.0019 - sparse_categorical_accuracy: 0. - ETA: 2:08 - loss: 0.0023 - sparse_categorical_accu - ETA - ET - ETA: 1:58 - loss: 0.0026 - sparse_categoric - ETA: 1:56 - loss: 0.0027 - sparse_categorical_accuracy: 0.9 - ETA: 1:56 - loss: 0.0027 - spar - ETA: 1: - ETA: 0s - loss: 0.0015 - sparse_categorical_accurac\n",
      "Epoch 168/200\n",
      "3516/3516 [==============================] - 167s 47ms/step - loss: 0.0015 - sparse_categorical_accuracy: 0.9998 - val_loss: 12825.3701 - val_sparse_categorical_accuracy: 0.9902se_categorical_accuracy: 0 - ETA: 2:32 - loss: 0.0021 - sparse_ - ETA: 2:21 - - ETA: 2:09 - loss: 0.00 - ETA: 2:05 - loss: 0.0 - ETA: 1 - ETA: 1:56 - loss: 0.0024 - sparse_categorical_accuracy: 0.9 - ETA: 1:56 - loss: 0.0023 - sparse_categorical - ETA: 1:54 - loss: 0.0023 - s - ETA: 1:52 - loss: 0.0022 - sparse_categorical_acc - ETA: 1:51 - loss: 0.0021 - sparse_categorical_accurac - ETA: 1:50 - loss: 0.0022 - sparse_categorical_ac - ETA: 1:48 - loss: 0.0022 - sparse_categorical_accuracy: 0 - ETA: 1:48 - loss: 0.0022 - sparse_categorical_accur - ETA: 1:47 - lo - ETA: 1:36 - loss: 0.0020 -  - ETA: 1:33 - loss: 0.0020 - spa - ETA: 1:31 - loss: 0.0023 - sparse_categori - ETA: 1:24 - loss: 0.0023 - sparse_categorical_accuracy: 0.9 - ETA: 1:23 - loss: 0.0023 - sparse_catego - ETA: 1:21 - loss: 0.0023 - sparse_categorical_ac - ETA: 1:20 - loss: 0.0023 - sparse_categorical_ - ETA: 1:18 - loss:  - ETA: 1:14 - loss: 0.0023 - sparse_categor - ETA: 22s - loss: 0.0016 - \n",
      "Epoch 169/200\n",
      "3516/3516 [==============================] - 164s 47ms/step - loss: 0.0012 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.5625 - val_sparse_categorical_accuracy: 0.9903oss: 1.7837e-04 - sparse_cat - ETA: 2:19 - - ETA: 2:09 - loss: 8.8896e-04 - sparse_categorica - ETA: 2:02 - loss: 7.7576e-04 - sparse_catego - ETA:  - ETA: 1:56 - loss: 8.8780e-04 - sparse_categorical_acc - ETA: 1:56 - loss: 8.7490e-04 - sparse_categorical_accuracy: - ETA: 1:56 - loss: 8.6730e-04 - sparse_categorical_ - ETA: 1:54 - loss: 8.4468e-0 - ETA: 1:51 - loss: 0.0010 - sparse_categorical_accurac - ETA: 1:51 - loss: 0.0010 - sparse_categorical_accurac - ETA: 1:50 - loss: 0.0010 - sparse_ca - ETA: 1:43 - loss - ETA: 1:40 - loss: 0.0012 - sparse_categorical_accuracy:  - ETA: 1:40 - loss: 0.0012 - spar - ETA: 1:27 - loss: 0.0011 - sparse_categorical_accurac - ETA: 1:26 - loss: 0.0011 - spars - ETA: 1:23 - loss: 0.0010 - sparse_categorical_accu - ETA: 1:22 - loss: 0.0010 - sparse_categorical_accuracy: 0.9 - ETA: 1: - ETA: 7s - loss: 0.0012 - sparse_categorical_acc - ETA: 6s - loss: 0.0012 - sparse_ca - ETA: 4s - l\n",
      "Epoch 170/200\n",
      "3516/3516 [==============================] - 167s 47ms/step - loss: 0.0020 - sparse_categorical_accuracy: 0.9998 - val_loss: 2621.2673 - val_sparse_categorical_accuracy: 0.9893 2:43 - loss: 0.0011 - sparse_categorical - ETA: 2 - ETA: 2:31 - loss: 9.5188e-04  - ETA: 2:28 - loss: 0.0012 - sparse_categorical_accuracy: 0 - ETA: 2:28 - loss: 0.0012 - sparse_cat - ETA: 2:22 - loss: 0.0010 - sparse_c - ETA: 2:12 - loss: 8.9502e-04 - sparse_ - ETA:  - ETA: 1:38 - loss: 0.0019 - sparse_categorical_acc - ETA: 1:37 - l - ETA: 1:34 - loss: 0.0021 - sparse_categorical_accuracy: 0.9 - E - ETA: 1:25 - loss: 0.0019 - sparse_categorical_accuracy: - ETA: 1:24 - loss: 0.0019 - sparse_categorical_accurac - ETA: 1:24 - loss: 0.0019 - sparse_categorical - ETA: 1:22 - loss: 0 - ETA: 1:19 - loss: 0.0019 - sparse_categorical_ac - ETA: 1:17 - loss: - ETA: 1:13 - loss: 0.0018 - sparse_ - ETA: 1:11 - loss: 0.0018 - sparse_categorical_accuracy: 0. - ETA: 1:11 - loss:  - ETA: 28s - lo - ETA:  - ETA: 24s - loss: 0.0021 - sparse_ - ETA: 23s - loss: 0.0021 - s - ETA: 22s - loss - ETA: 20s -  - ETA:  - ETA: 10s - loss: 0.0021 - sparse_categorical_accuracy:  - ETA: 10s - loss: 0.0021 - sparse_categorical_acc - ETA: 9s - loss: 0.0021 - sparse_cate - ETA: 7s - loss: 0.0021  - ETA: 4s - lo\n",
      "Epoch 171/200\n",
      "3516/3516 [==============================] - 166s 47ms/step - loss: 0.0013 - sparse_categorical_accuracy: 0.9998 - val_loss: 5.7971 - val_sparse_categorical_accuracy: 0.9892- ETA: 2:43 - loss: 0. - ETA: 2:39 - loss: 0.0012 - sparse_categorical_accura - ETA: 2:32 - loss: 8.4007e-04 - sparse_catego - ETA: 2: - ETA: 2:2 - ETA: 2:26 - loss: 7.9039e-04 - sparse_categorica - ETA: 2: - ETA: 2:12 - loss: 6.4657e-04 - sparse_cat - ETA: 1:56 - loss:  - ETA: 1:22 - - ETA:  - ETA: 1:13 - loss: 9.6578e-04 - sparse_cate - ETA: 1:11 - loss: 9.5495e-04 - sparse_c - ETA: 1:09 - loss: 9.3807e-0 - ETA: 10s - loss: 0.0013 - sparse_categori - ETA: - ETA: 4s - loss: 0.0013 - sparse_categorical_accura - ETA: 3s - loss: 0.00\n",
      "Epoch 172/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0013 - sparse_categorical_accuracy: 0.9998 - val_loss: 19.7114 - val_sparse_categorical_accuracy: 0.9898rse_categorical_accuracy - ETA: 24s - loss - ETA: 22s - lo - ETA: 14s - loss: 0.0014 - sparse_categori - ETA: 13s - loss: 0.0014 - sparse_catego - ETA: 12s - loss: 0.0014 - sparse_categorical_accuracy:  - ETA: 12s - loss: 0.0014 - - ETA: 11s - loss: 0.0014 - sparse_categorical_accuracy:  - ETA: 11s - loss: 0.0014 - sparse_categorical_accuracy:  - ETA: 10s - loss: 0.0014 - sparse_categorical_a\n",
      "Epoch 173/200\n",
      "3516/3516 [==============================] - 160s 45ms/step - loss: 0.0013 - sparse_categorical_accuracy: 0.9998 - val_loss: 19.8529 - val_sparse_categorical_accuracy: 0.9885 loss: 0.0027 - sparse_categorical_accuracy - ETA: 2:15 - loss: 0.0027 - sparse_categorical_accuracy: 0.9 - ETA: 2:14 - loss: 0.0026 - sparse_ - ETA: 2:06 - loss: 0.0021 - sparse - ETA: 2:03 - ETA: 1:59 - loss: 0.0017 - spars - ETA: 1:50 - loss: 0.0014 - sparse_categorical_accuracy: 0. - ETA: 1:50 - los - ETA: 1:46 - loss: 0.0014 - sparse_catego - ETA: 1:44 - loss: 0.0015 - sparse_categorical_accuracy: 0 - ETA: 1:43 - loss: 0.0015 - sparse_categoric - ETA: 1:42 - loss: 0.0015 - sparse_cat - ETA: 1: - ETA: 1:34 - loss: 0.0014 - sparse_categorical_accuracy: 0 - ETA: 1:34 - loss: 0.0014 - sparse_categorical_accura - ETA: 1:33 - loss: 0.0014 - sparse_ca - ETA: 1:31 - loss: 0.0014 - sparse_categorical_accura - ETA: 1:30 - loss: 0.0014 - spa - ETA: 1:27 - loss: 0.0015 - sparse_categori - ETA: 1:25 - loss: 0.0015 - sparse_categorical_accuracy: 0 - ETA: 1:25 - loss: 0.0015 - sparse_cate - ETA: 1:23 - loss: 0.0015 - ETA: 1:19 - los - ETA: 1:15 - loss: 0.0014 - sparse_categor - ETA: 1:13 - l - ETA: 1:03 - loss: 0.0017 - sparse_categorical_accuracy: - ETA: 3s - loss: 0.001 - ETA: 0s - loss: 0.0013 - sparse_categorical_accuracy: 0.99\n",
      "Epoch 174/200\n",
      "3516/3516 [==============================] - 159s 45ms/step - loss: 0.0014 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.2009 - val_sparse_categorical_accuracy: 0.99052:25 - loss: 0.0031 - spar - ETA: 2:22 -  - ETA: 2:18 - loss:  - ETA: 2:14 - loss: 0.0024 - sparse_categorical_accuracy: 0 - ETA: 2:13 - loss: - ETA: 2:09  - ETA: 2:05 - loss: 0.0018 - sparse_categorical_accurac - ETA: 1:58 - loss: 0.0016 - sparse_categorical_accuracy: 0.9 - ETA: 1:58 - loss: 0.0016 - sparse_categorical_accurac - ETA: 1:57 - ETA: 1:35 - loss: 0.0016 - spa - ETA: 1:32 - loss: 0.0016 - sparse_categorical_accuracy: 0.999 - ETA: 1:32 - loss: 0.0016 - sparse_categorical_accuracy: 0. - ETA: 1:31 - loss: 0.0016 - sparse_categorical_accuracy: 0. - ETA: 1:31 - loss: 0.0016 - spar - ETA: 1:28 - loss: 0.0016  - ETA: 1:25 \n",
      "Epoch 175/200\n",
      "3516/3516 [==============================] - 156s 44ms/step - loss: 0.0012 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.2121 - val_sparse_categorical_accuracy: 0.9890\n",
      "Epoch 176/200\n",
      "3516/3516 [==============================] - 153s 44ms/step - loss: 0.0017 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.3163 - val_sparse_categorical_accuracy: 0.9886\n",
      "Epoch 177/200\n",
      "3516/3516 [==============================] - 152s 43ms/step - loss: 0.0013 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.2672 - val_sparse_categorical_accuracy: 0.9899\n",
      "Epoch 178/200\n",
      "3516/3516 [==============================] - 160s 46ms/step - loss: 0.0019 - sparse_categorical_accuracy: 0.9997 - val_loss: 5309.5259 - val_sparse_categorical_accuracy: 0.9896.0018 - sparse_categorical - ETA: 7s - loss: 0.0017 - sparse_categorical_ac - ETA: 6s - loss: 0.0018 - sparse_categorical_accur - ETA: 5s - loss: 0.0019 - s - ETA: 2s - loss: 0.0019 - sparse_categorical_accura - ETA: 1s - loss: 0.0019 - sparse_categorical_accuracy: 0.999 - ETA: 1s - loss: 0.0019 - sparse_cat\n",
      "Epoch 179/200\n",
      "3516/3516 [==============================] - 159s 45ms/step - loss: 0.0012 - sparse_categorical_accuracy: 0.9998 - val_loss: 33619.4023 - val_sparse_categorical_accuracy: 0.9893\n",
      "Epoch 180/200\n",
      "3516/3516 [==============================] - 161s 46ms/step - loss: 0.0016 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.3643 - val_sparse_categorical_accuracy: 0.9899TA: 2:08 - loss: 0.0021 - spa - ETA: 2:05 - loss: 0.0023 - sparse_categorical_accuracy: 0.9 - ETA: 2:05 - loss: 0.002 - ETA: 1:55 - loss: 0.0021 - sparse_categorical_accuracy: 0.999 - ETA: 1:55 - loss: 0.0021 - sparse_categorical_accura - ETA: 1:54 - loss: 0.0021 - sparse_categorical - ETA: 1:53 - loss: 0.0020 - sparse_categorical_acc - ETA: 1:52 - loss: 0.0020 - sparse_categorical_accuracy - ETA: 1:51 - loss: 0.0019 - sparse_categorical_accura - ETA: 1:50 - loss: 0.0019 - sparse_categorical_accu - ETA: 1:49 - loss: 0.0019 - sparse_categ - ETA: 1:41 - loss:  - ETA: 1:31 - loss: 0.0018 - sparse_categorical_accura - ETA: 1:30 - loss: 0. - ETA: 1:21 -  - ETA: 1:04 - loss: 0.0017 - sparse_categorical_ - ETA: 1:03 - loss: 0 - ETA: 48s - loss: 0.0017 - sparse_categorical_accuracy:  - ETA: 48s - loss: 0.0017 - sparse_categorical_accura - ETA: 47s - loss: 0.00 - ETA: 44s - loss: 0.0016 - sparse_categorical_accu - ETA: 43s - loss: 0.0016 - sparse_categorical_accuracy - E - ETA: 41s - loss: 0.0017 - sparse_categorical_accuracy: 0.99 - ETA: 41s - loss: 0.0017 - sparse_categorical_accuracy: 0.99 - ETA: 41s - loss: 0.0017 - sparse_categorical_accu - ETA: 40s - loss: 0.0017 - sparse_categori - ETA: 39s -  - ETA: 38s - loss: 0.0017 - sparse_categorical_ac - ETA: 37s - loss: 0.0017 - sparse_categorical_accura - ETA: 37s - loss: 0.0017 - sparse_categorical_accuracy - ETA: 36s - loss: 0.0017 -\n",
      "Epoch 181/200\n",
      "3516/3516 [==============================] - 157s 45ms/step - loss: 0.0020 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.3131 - val_sparse_categorical_accuracy: 0.99037s - loss: 0.0021 - sparse_categorical_ - ETA - ETA: 12s - loss: 0.0021 - sparse_categorical_accuracy: 0.99 - ETA: 12s - loss: 0.0021 - sparse_categorical_accuracy:  - ETA: 12s - loss:  - ETA: 10s  - ETA: 3s - loss: 0.0020 - sparse_categorical_accuracy:  - ETA: 2s - loss: 0.0020 - sparse_categorical_accuracy: - ETA: 2s - loss: 0.0020 - sparse_categorical_a - ETA: 1s - loss: 0.0020 - sparse_categorical_accur - ETA: 0s - loss: 0.0020 - sparse_categorical_accuracy - ETA: 0s - loss: 0.0020 - sparse_categorical_accuracy: 0.9\n",
      "Epoch 182/200\n",
      "3516/3516 [==============================] - 160s 45ms/step - loss: 0.0019 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.2585 - val_sparse_categorical_accuracy: 0.99010.99 - ETA: 6:18 - loss: 7.7970 - ETA: 3:26 - - ETA: 2:51 - loss: 0.0020 - sparse_categorical_ac - ETA: 2:47 - loss: 0.0017 - sparse_categorical_accuracy: 0.9 - ETA: 2:46 - loss: 0.0019 - sparse_ - ETA: 2 - ETA: 2:30 - loss: 0.00 - ETA: 17s - loss: 0.0019 - sparse_categori - ETA: 16s - loss: 0.0019 - sparse_categorical_\n",
      "Epoch 183/200\n",
      "3516/3516 [==============================] - 160s 46ms/step - loss: 0.0022 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.6802 - val_sparse_categorical_accuracy: 0.9906se_cate - ETA: 1:07 - loss: 5.5176e-04 - sparse_categorical_accur - ETA: 1:06 - loss: 5.6181e-04 - sparse_categorical_accuracy: 0.9 - ETA: 1:06 - loss - ETA: 14s - loss: 0.0023 - sparse_categorical_accuracy - ETA: 14s - loss: 0.00 - ETA: 12s - loss: 0.0023 - sparse_categorical_ - ETA: 11s - loss: 0.0023 - sparse_catego - ETA: 10s - loss: 0.002 - ETA: 7s - loss: 0.0022 - sparse_categorical_a - ETA: 6s - loss: 0.0022 - sparse_categorical_ac - ETA\n",
      "Epoch 184/200\n",
      "3516/3516 [==============================] - 162s 46ms/step - loss: 0.0016 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.2816 - val_sparse_categorical_accuracy: 0.9897:33 - loss: 1.5082e-04 - sparse_categorical_accuracy: 0.9 - ETA: 2:33 - loss - ETA: 2:28 - loss: 2.7805e - ETA: 2:25 - loss: 3.8961e-04 - sparse_categorical - ETA: 2:17 - loss: 8.2884e-04 - sparse_categorical_accuracy: 0 - ETA: 2:17 - loss: 8.88 - ETA: 2:13 - loss: 7.6893e-04 - sparse_categorical_accuracy: 0.999 - ETA: 2:12 - loss: 7.6630e-04 - sparse_cate - ETA: 2:10 - loss: - ETA: - ETA: 1:54 - loss: 5.9838e-04 - sparse_ - ETA: 1:52 - loss: 5.7649e-04 - sparse - ETA: 1:49 - loss: 5.4636e-04 - sparse_categorical_acc - ETA: 1:48 - loss: 5.3401e-04 - sparse_categorical_accuracy: 0.999 - ETA: 1:48 - loss - ETA: 1:43 - loss: 5.8894e- - ETA: 1:40 - loss: 6.7948e-04 - sparse_categorical_accurac - ETA: 1:39 - loss: 6.7693e-04 - sparse_categorical_a - ETA: 1:25 - loss: 8.8786e - ETA: 1:16 - loss: 9.3620e-04 - sparse_catego - ETA: 1:14 - los - ETA: 1:09 - loss: 9.9805e-04 - sparse_categorical_accuracy: 0.99 - ETA: 1:09 - loss: 9.9774e-04 - sparse_categorical_accuracy: 0.9 - ETA: 1:09 - loss: 9.9557e-04 - sparse_categorical_accuracy: 0.999 - ETA: 1:09 - loss: 9.9458e-04 - sparse_categorical_accura -  - ETA: 1:02 - loss: 9.9117e-04 - sparse_categorical_accuracy: 0.999 - ETA: 1:02 - loss: 9.9025e-04 - sparse_cat - ETA: 1:00 - loss: 9.7165e-04 - ETA: 58s - loss: 0.0011 - sparse_categorical_accu - ETA: 57s - loss: 0.0011 - sparse_ca - ETA: 42s - loss: 0.0014 - sparse_categorical_ - ETA: 41s  - ETA: 33s - loss: 0.0015 - sparse_categorical_accuracy:  - ETA: 33s - loss: 0.0015 - sparse_ca - ETA: 29s - loss: 0.0015 - sparse_categorical_accu - ETA: 28 - ETA: 23s - loss: 0.0015 - s - ETA: 22s - loss: 0.0015 - sparse_categorical_accu - ETA: 21s  - ETA: 20s - loss: 0.0016 - sparse_catego - ETA: 19s - lo - ETA - ETA: 15s - loss: 0.0016 - sparse_categorical_accuracy: 0.99 - ETA: 15 - ETA: 13s - loss: 0.0016 - sparse_categorical_accuracy:  - ETA: 13 - ETA: 11s - loss - ETA: 8s - loss: 0.0016 - sparse_c - ETA: 6s - loss: 0.0016 - sparse_categorical_a - ETA: 5s - loss: 0.0016 - sparse_categori - ETA: 3s - loss: 0.0016 - sparse_categorical_accuracy: 0. - ETA: 2s - loss: 0.0016 - sparse_categorical_accuracy: 0.999 - ETA: 2s - loss: 0.0016 - sparse_categ - ETA: 0s - loss: 0.0016 - sparse_categorical_accuracy: 0.999 - ETA: 0s - loss: 0.0016 - sparse_categorical_acc\n",
      "Epoch 185/200\n",
      "3516/3516 [==============================] - 163s 46ms/step - loss: 0.0016 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.2208 - val_sparse_categorical_accuracy: 0.989904 - sparse_categorical_accuracy - ETA: 2:37 - loss: 6.0911e-04 - sparse_categori - ETA: 2:36 - l - ETA: 2:33 - loss: 4.0390e-04 - sparse_categori - ETA: 2:31 - loss: 4.3021e-04 - spars - ETA: 2:29 - loss: 3.7867e - ETA: 2:20 - loss: 9.4508e-04 - - ETA: 2:09 - loss: 9.0296e-04 - sparse_ - ETA: 2:07 - loss: 8.4154e-04 - sparse_categorical_accura - ETA: 2:06 - l - ETA: 2:01 - loss: 0.0012 - sparse_categorical_a - ETA: 1:59 - loss: 0.0012 - sparse_catego - ETA: 1:57 - ETA: 1:52 - loss: 0.0011 - sparse_categorical_a - ETA: 1:51 - loss: 0.0011 - sparse_categorical_accurac - ETA: 1:50 - loss: 0.0011 - sparse_categorical_accuracy: 0 - ETA: 1:50 - loss: 0.0011 - sparse_categorical_ac - ETA: 1:49 - loss: 0.0011 - sparse_categorical_accu - ETA: 1:48 - loss: 0.0011 - sparse_categorical_acc - ETA: 1:46 - loss: 0.0011 - sparse_categorical_accu - ETA: 1:45 - loss: 0.0011 - sparse_categorical_ - ETA: 1:44 - loss: 0.0012 - sparse_cate - ETA: 1:41 -  - ETA: 1:37 - loss: 0.0012 - sparse_categorical_accuracy: 0. - ETA: 1:37 -  - ETA: 1:32 - loss: 0.0011 - sparse_categorical_accuracy: 0 - ETA: 1:32 - loss: 0.0011 - sparse - ETA: 1:29 - loss: 0.0 - ETA: 23s - loss: 0.0018 - sparse_catego - ETA: 13s - loss: 0.0017 - sparse_categorical_accura - ETA: 13s\n",
      "Epoch 186/200\n",
      "3516/3516 [==============================] - 168s 48ms/step - loss: 9.5316e-04 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.2654 - val_sparse_categorical_accuracy: 0.98975 - sparse_ca - ETA: 2:24 - lo - ETA: 2:20 - loss: 9.2384e-0 - ETA: 2:16 - loss: 8.1939e-05 - sparse_categorical_accuracy: 1.00 - ETA: 2:16 - loss: 8.1589e-05 - spa - ETA: 2:14 - loss: 2.0804e-04 - sparse_categorical_accuracy: 0.99 - ETA: 2:13 - loss: 2.0669e-04 - sparse_ - ETA: 2:11 - loss: 2.8420e-04 - sparse_categorical_accuracy: 0.999 - ETA: 2:11 - loss: 2.8348e-04 - sparse_categorical_accur - ETA: 2:10 - loss: 2.7775e-04 - sparse_categorical_accura - ETA: 2:09 - loss: 2.9523e-04 - sparse_categorical_accuracy: 0 - ETA: 2:09 - loss: 3.7444e-04 - sparse_categorical_accuracy: 0. - ETA: 2:08 - loss: 3.7249e-04 - sparse_categori - ETA: 2:07 - loss: 3.7741e-04 - sparse_categori - ETA: 2:05 - loss: 4.051 - ETA: 2:01 - loss: 5.6687e-04 - spar - ETA: 1:58 - loss: 6.4404e-04 - sparse_categorical_accura - ETA: 1:57 - loss: 6.3832e-04 - sparse_ca - ETA: 1:55 - loss: 6.4197e-04 - sparse_categorical_accura - ETA: 1:54 - loss: 6.4056e-04 - sparse_cate - ETA: 1:52 - loss: 6.1629e-04 - sparse_categorical_accuracy: 0.99 - ETA: 1:52 - loss: 6.1409e-04 - sparse_categorical_a - ETA: 1:50 - loss: 5.9847e-04 - sparse_categorical_accuracy: - ETA: 1:50 - loss: 6.1291e-04 - sparse_categorical - ETA: 1:48 - loss: 9.1978e-04 - sparse_categorical_accur - ETA: 1:47 - loss: 9.0351e-04 - sparse_categorical_accuracy: 0. - ETA: 1:47 - loss: 8.9906e-04 - sparse_categorica - ETA: 1:47 - - ETA: 1:44 - lo - ETA: 1:41 - loss: 8.4682e-04 - sparse_ - ETA: 1:40 - loss: 8.6592e-04 - sparse_categorical_accuracy: - ETA: 1:39 - loss: 8.6104e-04 - sparse_catego - ETA: 1:38 - loss: 8.5081e-04 - sparse_categorical_accurac - ETA: 1:38 - loss: 9.8932e-04 - sparse_catego - ETA: 1:36 - loss: 9.7153e-04 - sparse_categorical_accuracy:  - ETA: 1:36 - loss: 9.6456e-04 - sparse_categorical_accurac - ETA: 1:35 - loss: 9.5507e-04 - sparse_categoric - ETA: 1 - ETA: 1:28 - loss: 8.8969e-04 - sparse_categor - ETA: 1:27 - loss: 8.7572e-04 - sparse_categorica - ETA: 1:26 - loss: 8.6326e-04 - spars - ETA: 1:24 - loss: 8.4536e-04 - sparse_categorical_accuracy: 0. - ETA: 1:24 - loss: 8.4253e-04 - spars - ETA: 1:21 - loss: 8.1728e-04 - sparse_categorica - ETA: 1:19 - loss: 8.3145e-04 - sp - ETA: 1:16 - loss: 8.6 - ETA: 1:11 - loss: 8.3266e-04 - sparse_categorical_accuracy: 0.99 - ETA: 1:11 - loss: 8.3132e-04 - sparse_categorical_accur - ETA: 1:11 - loss: 8.2495e-04 - sparse_categorical_accuracy: 0.999 - ETA: 1:11 - loss: 8.2454e-04 - sparse_categorical_accuracy: - ETA: 1:10 - loss: 8.2069e-04 - sparse_categorical_accu - ETA: 1:09 - loss: 8.1321e - ETA: 1:06 - loss: 7.8708e-04 - sparse_c - ETA: 45s - loss: 7.9044e-04 - s - ETA: 44s - loss: 7.8070e-04 - sparse_categorical_accuracy:  - ETA: 37s - loss: 8.60 - ETA: 36s - loss: 8.5138e-04 - sparse_categorical_ac - ETA: 7s - loss: 9.1572e-04 - sparse_categori\n",
      "Epoch 187/200\n",
      "3516/3516 [==============================] - 164s 47ms/step - loss: 0.0012 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.4231 - val_sparse_categorical_accuracy: 0.989304 - sparse_categorical_accuracy: 0.999 - ET - ETA: 1:57 - loss: 6. - ETA: 1:50 - loss: 5.5633e-04 - sparse - ETA: 1:48 - loss: 6.2459e-04 - sparse_categori - ETA: 1:40 - loss: 6.2194e-04 - sparse_categorical_ac - ETA: 1:39 - loss: 6.5671e-04 - sparse_categorical_a - ETA:  - ETA: 1:32 - loss: 6.5163e-04 - spa - ETA: 1:30 - loss: 6.3055e-04 - sparse_categor - ETA: 1:28 - loss: 6.1625e-04 - sparse_categorical_accuracy: 0. - ETA: 1:28 - loss: 6.1361e-04 - sparse_categorical_ac -\n",
      "Epoch 188/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0020 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.2888 - val_sparse_categorical_accuracy: 0.98843521e-04 - sparse_categorical_ - ETA: - ETA: 2:22 - loss: 0.0020 - - ETA: 2:20 - l - ETA: 2:15 - loss: 0.0014 - sparse_categorica - ET - ETA: 1:58 - loss: 0.0012 - sparse_cat - ETA: 1:55 - loss: 0.0011 - spa - ETA: 1:53 - l - ETA: 1:48 - loss: 9.4621e-04 - sparse_categorical_accuracy:  - ETA: 1:48 - loss: 9.3599e-04 - sparse_ - ETA: 1:45 - loss: 0.0 - ETA: 1:36 - loss: 0.0017 - sparse_categorical - ETA: 1:35 - loss: 0.0017 - sparse_categorical_accuracy: 0.999 - ETA: 1:34 - loss: 0.0017 - sparse_categorical_accuracy: 0.99 - ETA: 1:34 - loss: 0.0017 - sparse_c - ETA: 1:32 - loss: 0.0016 -  - ETA: 1:29 - loss: 0.0015  - ETA: 1:25 - loss: 0.0015 - sparse_cate - ETA: 1:17 - loss: 0.0 - ETA: 1 - ETA: 1:09 - loss: 0.0015 - spars - ETA: 23s - loss - ETA: 19s - loss: 0.0012 - sparse_categorical_ac - ETA: 18s - loss: 0.0012 - sparse_categorical_accuracy: 0. - ETA: 15s - l\n",
      "Epoch 189/200\n",
      "3516/3516 [==============================] - 159s 45ms/step - loss: 0.0015 - sparse_categorical_accuracy: 0.9998 - val_loss: 39.2707 - val_sparse_categorical_accuracy: 0.9900 - ETA: 1:56 - loss: 0.0016 - sparse_categorical_a - ETA: 1:55 - loss: 0.0016 - sparse - ETA: 1:42 - loss: 0.0013 - sparse_categorical_accuracy: 0. - ETA: 1:41 - loss: 0.0013 - sparse_categor - ETA: 1:40 - loss: 0.0013 - sparse_categorical_a - ETA: 1:38 - loss: 0.0012 - sparse_cate - ETA: 1:26 - lo - ETA: 1:21 - loss: 0.0011 - sparse_categorical_accur - ETA: 1:20 - loss: 0.0011 - sparse_cat - ETA: 1:18 - loss: 0.0011 - sparse_categorical_accuracy: - ETA: 1:17 - - ETA: 1:13 - loss: 0.0010 - sparse_categorical_accuracy: 0. - ETA: 1:13 - loss: 0.0010 - sparse_categorical_accuracy: 0. - ETA: 1:12 - loss: 0.0010 - sparse_categorical_accurac - ETA: 1:12 - loss: 0.0010 - sparse_categorical_ - ETA: 1:10 - loss: 0.0010 - sparse_catego - ETA: 1:08 - loss: 9.9432e-04 - sparse_categorical_accura - ETA: 1:08 - loss: - ETA:  - ETA: 33s - loss: 0.0016 - - ETA: 20s - loss: 0.0016 - sparse_categorical_accuracy:  - ETA: 20s - loss: 0.0016 - spars - ETA: 18s - loss: 0.0016  - ETA: 1s - loss: 0.0016 - sparse_categorical_a - ETA: 0s - loss: 0.0016 - sparse_categorical_accuracy\n",
      "Epoch 190/200\n",
      "3516/3516 [==============================] - 159s 45ms/step - loss: 0.0012 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.2374 - val_sparse_categorical_accuracy: 0.9901oss: 0.0011 - sparse_cate - ETA: 1:58 - loss: 0.0011 - sparse_ca - E - ETA: 46s - loss: 9.0563e-04 - sparse_ca - ETA: 45s - loss: 8.9775e-04 - s - ETA: 41s - lo - ETA: 29s - loss: 0.0012 - sparse_categorical_accuracy - ETA: 29s - los\n",
      "Epoch 191/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0020 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.2250 - val_sparse_categorical_accuracy: 0.98910. - ETA: 2:38 - loss: 4.8843e-04 - sparse_categorical_accu - ETA: 2:36 - loss: 9.1429e-04 - sparse_categ - ETA: 2:34 - loss: 0.0081 - sparse_categorical_accurac - ETA: 2:33 - loss: 0.0072 - sparse_categorica - ETA: 2:31 - loss: 0.0066 - sparse_categorical_accuracy: 0.999 - ETA: 2:30 - loss: 0.0065 - sparse_categorical_accu - ETA: 2:29 - loss: 0.0057 - sparse_categorical_accuracy: 0.9 - ETA: 2:29 - loss: 0.0056 - spars - ETA: 2:25 - loss: 0.0055 - sparse_c - ETA: 2:23 - loss: 0.0052 - sparse_categorical_accuracy - ETA: 2:16 - loss: 0.0037 - sparse_categor - ETA: 2:14 - loss: 0.0036 - sparse_categ - ETA:  - ETA: 2:02 - loss: 0.0023 -  - ETA: 1:58 - loss: 0.0021 - sparse_categorical_accuracy: 0.9 - ETA: 1:58 - loss: 0.0021 - sparse_ca - ETA: 1:56 - loss: 0.0020 - sparse_categori - ETA: 1:54 - loss:  - ETA: 1:51 - loss: 0.0 - ETA: 1:36 - loss: 0. - ETA: 1:32 - loss: 0.0014 - sparse_categorical_accu - ETA: 1:31 - los - ETA: 1s - loss: 0.0020 - sparse_categorica - ETA: 0s - loss: 0.0020 - sparse_categorical_accuracy: 0.999\n",
      "Epoch 192/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0010 - sparse_categorical_accuracy: 0.9998 - val_loss: 542.1512 - val_sparse_categorical_accuracy: 0.9890ETA: 16s - loss: 0.0010 - ET - ETA: 2s - loss: 0.0010 - sparse_c\n",
      "Epoch 193/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 9.1281e-04 - sparse_categorical_accuracy: 0.9998 - val_loss: 22536.8047 - val_sparse_categorical_accuracy: 0.9898- ETA: 2:00 - loss: 0.0013 - sparse_categorical_accuracy: - ETA: 2:00 - loss: 0.0013 - sparse_ - ETA: 1:57 - loss: 0.0012 - sparse_categorical_accurac - ETA: 1:57 - loss: 0.0012 - spars - ETA: 1:54 - loss: 0.0012 - sparse_categorical_accuracy:  - ETA: 1:53 - - ETA: 1:43 - loss: 9.4335 - ETA: 8s - loss: 8.9418e-04 - sparse_categorical_accuracy: 0.999 - ETA: 8s - loss: 8.9366e-04 - sparse - ETA: 5s - loss: 9.0713e-04 - sparse_categorical_accuracy: 0.9 - ETA:\n",
      "Epoch 194/200\n",
      "3516/3516 [==============================] - 159s 45ms/step - loss: 0.0014 - sparse_categorical_accuracy: 0.9998 - val_loss: 1554.7810 - val_sparse_categorical_accuracy: 0.9896arse_c - ETA: 2:17 - loss: 2.2429e-04 - sparse_categorical_accuracy:  - ETA: 2:16 - - ETA: 2:12 - loss: 2.3633e-04 - sparse_categorical_ - ETA: 1:58 - loss: 2.4165e-04 - sparse_categorical_accuracy: 0.999 - ETA: 1:58 - loss: 2.4115e-04 - sp - ETA: 1:55 - loss: 2.9502e-04 - sparse_categorica - ETA: 1:53 - loss: 3.4441e- - ETA: 1:38 - loss: 3.2559e-04 - sparse_categorical_accura - ETA: 1:37 - loss: 3.2098e-04 - sparse - ETA: 1:35 - loss: 3.0815e- - ETA:  - ETA: 46s - loss: 9.5847e-04  - ETA: 1s - loss: 0.0014 - sparse_categorica\n",
      "Epoch 195/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0020 - sparse_categorical_accuracy: 0.9998 - val_loss: 3.0466 - val_sparse_categorical_accuracy: 0.9897- sparse_categ - ETA: 2:05 - loss: 0.0027 -  - ETA: 2:02 - loss: 0.0026 - sparse_categorical_accuracy: 0.999 - ETA: 2:02 - ETA: 32s - loss: 0.0021 - sparse_categorica - E - ETA: 11s - loss:  - ETA: 10s - loss: 0.0022 - sparse_categor - ETA: - ETA: 3s - loss: 0.0021 - sparse_categorical_accuracy: 0.999 - ETA: 3s - loss: 0.0021 - sparse_categorica - ETA: 2s - loss: 0.0021 - sparse_categorical_accuracy: - ETA: 1s - loss: 0.0020 - sparse_categoric\n",
      "Epoch 196/200\n",
      "3516/3516 [==============================] - 152s 43ms/step - loss: 0.0019 - sparse_categorical_accuracy: 0.9998 - val_loss: 71.2805 - val_sparse_categorical_accuracy: 0.9895\n",
      "Epoch 197/200\n",
      "3516/3516 [==============================] - 156s 44ms/step - loss: 0.0015 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.1560 - val_sparse_categorical_accuracy: 0.9902- sparse_catego - ETA: 8s - loss: 0.0014 \n",
      "Epoch 198/200\n",
      "3516/3516 [==============================] - 158s 45ms/step - loss: 0.0021 - sparse_categorical_accuracy: 0.9997 - val_loss: 12185.9131 - val_sparse_categorical_accuracy: 0.9908 loss: 0.0031 - sparse_categorical_accu - ETA: 1:18 - - ETA: 15s - loss: 0.0021 - sparse_catego - ETA: 14s - loss: 0.0021 - sparse_categorical_accuracy: 0.99 - ETA: 14s - loss: 0.0021 - \n",
      "Epoch 199/200\n",
      "3516/3516 [==============================] - 152s 43ms/step - loss: 0.0090 - sparse_categorical_accuracy: 0.9997 - val_loss: 7387.3657 - val_sparse_categorical_accuracy: 0.9888\n",
      "Epoch 200/200\n",
      "3516/3516 [==============================] - 150s 43ms/step - loss: 9.6642e-04 - sparse_categorical_accuracy: 0.9999 - val_loss: 16.3740 - val_sparse_categorical_accuracy: 0.9900\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 16.3739 - sparse_categorical_accuracy: 0.9900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[16.373878479003906, 0.9900000095367432]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.device('/device:GPU:0')\n",
    "model.fit(x_train, y_train, epochs=200, batch_size=128, validation_data=(x_test, y_test))\n",
    "\n",
    "model.evaluate(x_test,  y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "30b279828ae1e7e7bc0391f222e646253ead875e1ad934e3789f24cec7b73e81"
  },
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
