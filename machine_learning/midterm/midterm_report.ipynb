{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TS1Yus4opatH"
      },
      "source": [
        "# 기계학습 중간고사 대체 레포트\n",
        "\n",
        "\n",
        "**문제안내**\n",
        " - 본 레포트는 1) 기대수명 예측문제 2) 숫자이미지 예측문제 두 가지 문제를 회귀와 분류로 각각 풀어보는데 목적이 있습니다. 1)기대수명 예측문제는 회기로 풀어야 할 문제로 보이나 분류로도 풀 수 있습니다. 반대로 2) 숫자이미지 예측문제도 분류문제로 보이나 회기 문제로 풀 수 있습니다. 2가지 문제를 회기와 분류 2가지 방법으로 풀어보고, 회기와 분류가 어떤 역할을 하고 어떤 문제에 적용해야 하는지에 대해 이해하면 좋겠습니다. 아래 안내를 참조해서 각 문제를 코딩하고 결과를 실험정리/분석 문서에 작성해서 제출해 주세요.\n",
        "\n",
        "**풀어야 할 문제**\n",
        " 1. 기대수명 예측하기 (회기/분류)\n",
        " 2. 숫자이미지 예측하기 (회기/분류) \n",
        "\n",
        "**제출해야 할 것**: 소스코드 (ipynb파일) + 실험정리/분석 문서 (pdf)\n",
        "\n",
        "**제출마감일**: 4월 29일 오후 5시\n",
        "\n",
        "**제출포맷**\n",
        " 1. 소스코드: ipynb 파일로 제출. 컴파일한 결과가 출력된 상태로 제출해야 합니다. 중간 결과가 출력되도록 코드를 작성하는 것을 추천합니다.\n",
        " 2. 실험정리/분석 문서: pdf 파일로 제출. 실험결과는 테이블 형태로 정리해야 하며 분석은 줄글로 작성 가능합니다. \n",
        "\n",
        "**소스코드**\n",
        "- 소스코드는 주석이 있는 것이 좋으며, 중간중간 결과를 출력해 보는 것을 추천합니다. [문제1]~[문제5] 부분에 여러분들이 직접 코딩을 한 후 ipynb 파일을 제출하면 됩니다.\n",
        "\n",
        "**실험정리/분석 문서**\n",
        "1. [문제1]~[문제5]의 결과를 테이블 하나에 정리하세요. 배점 10점\n",
        "2. [문제1]~[문제4]를 분석하세요. 회기(linear regression)이 분류(knn)에 비해 1)기대수명 예측 2)숫자이미지 예측 중 어떤 문제를 더 잘푸는지 분석하고, 왜 더 잘푸는지 설명하세요. 또한 분류(knn)이 회기(linear regression)에 비해 어떤 문제를 더 잘푸는지 분석하고, 그 이유를 설명하세요. 배점 20점 \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlWPs9zL5U_t"
      },
      "source": [
        "# 수명데이터 예측하기 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_ZqtpIk8dOh"
      },
      "source": [
        "data load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TUen9i2D5VPC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data_loc = 'https://github.com/dknife/ML/raw/main/data/'\n",
        "life = pd.read_csv(data_loc + 'life_expectancy.csv')\n",
        "life.dropna(inplace = True)\n",
        "\n",
        "X = life[['Alcohol', 'Percentage expenditure', 'Polio',\n",
        "         'BMI', 'GDP', 'Thinness 1-19 years']]\n",
        "y = life['Life expectancy']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Country</th>\n",
              "      <th>Year</th>\n",
              "      <th>Status</th>\n",
              "      <th>Life expectancy</th>\n",
              "      <th>Adult mortality</th>\n",
              "      <th>Infant deaths</th>\n",
              "      <th>Alcohol</th>\n",
              "      <th>Percentage expenditure</th>\n",
              "      <th>Hepatitis B</th>\n",
              "      <th>Measles</th>\n",
              "      <th>...</th>\n",
              "      <th>Polio</th>\n",
              "      <th>Total expenditure</th>\n",
              "      <th>Diphtheria</th>\n",
              "      <th>HIV/AIDS</th>\n",
              "      <th>GDP</th>\n",
              "      <th>Population</th>\n",
              "      <th>Thinness 1-19 years</th>\n",
              "      <th>Thinness 5-9 years</th>\n",
              "      <th>Income composition of resources</th>\n",
              "      <th>Schooling</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>2015</td>\n",
              "      <td>Developing</td>\n",
              "      <td>65.0</td>\n",
              "      <td>263.0</td>\n",
              "      <td>62</td>\n",
              "      <td>0.01</td>\n",
              "      <td>71.279624</td>\n",
              "      <td>65.0</td>\n",
              "      <td>1154</td>\n",
              "      <td>...</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.16</td>\n",
              "      <td>65.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>584.259210</td>\n",
              "      <td>33736494.0</td>\n",
              "      <td>17.2</td>\n",
              "      <td>17.3</td>\n",
              "      <td>0.479</td>\n",
              "      <td>10.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>2014</td>\n",
              "      <td>Developing</td>\n",
              "      <td>59.9</td>\n",
              "      <td>271.0</td>\n",
              "      <td>64</td>\n",
              "      <td>0.01</td>\n",
              "      <td>73.523582</td>\n",
              "      <td>62.0</td>\n",
              "      <td>492</td>\n",
              "      <td>...</td>\n",
              "      <td>58.0</td>\n",
              "      <td>8.18</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>612.696514</td>\n",
              "      <td>327582.0</td>\n",
              "      <td>17.5</td>\n",
              "      <td>17.5</td>\n",
              "      <td>0.476</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>2013</td>\n",
              "      <td>Developing</td>\n",
              "      <td>59.9</td>\n",
              "      <td>268.0</td>\n",
              "      <td>66</td>\n",
              "      <td>0.01</td>\n",
              "      <td>73.219243</td>\n",
              "      <td>64.0</td>\n",
              "      <td>430</td>\n",
              "      <td>...</td>\n",
              "      <td>62.0</td>\n",
              "      <td>8.13</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>631.744976</td>\n",
              "      <td>31731688.0</td>\n",
              "      <td>17.7</td>\n",
              "      <td>17.7</td>\n",
              "      <td>0.470</td>\n",
              "      <td>9.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>2012</td>\n",
              "      <td>Developing</td>\n",
              "      <td>59.5</td>\n",
              "      <td>272.0</td>\n",
              "      <td>69</td>\n",
              "      <td>0.01</td>\n",
              "      <td>78.184215</td>\n",
              "      <td>67.0</td>\n",
              "      <td>2787</td>\n",
              "      <td>...</td>\n",
              "      <td>67.0</td>\n",
              "      <td>8.52</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>669.959000</td>\n",
              "      <td>3696958.0</td>\n",
              "      <td>17.9</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.463</td>\n",
              "      <td>9.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>2011</td>\n",
              "      <td>Developing</td>\n",
              "      <td>59.2</td>\n",
              "      <td>275.0</td>\n",
              "      <td>71</td>\n",
              "      <td>0.01</td>\n",
              "      <td>7.097109</td>\n",
              "      <td>68.0</td>\n",
              "      <td>3013</td>\n",
              "      <td>...</td>\n",
              "      <td>68.0</td>\n",
              "      <td>7.87</td>\n",
              "      <td>68.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>63.537231</td>\n",
              "      <td>2978599.0</td>\n",
              "      <td>18.2</td>\n",
              "      <td>18.2</td>\n",
              "      <td>0.454</td>\n",
              "      <td>9.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Country  Year      Status  Life expectancy  Adult mortality  \\\n",
              "0  Afghanistan  2015  Developing             65.0            263.0   \n",
              "1  Afghanistan  2014  Developing             59.9            271.0   \n",
              "2  Afghanistan  2013  Developing             59.9            268.0   \n",
              "3  Afghanistan  2012  Developing             59.5            272.0   \n",
              "4  Afghanistan  2011  Developing             59.2            275.0   \n",
              "\n",
              "   Infant deaths  Alcohol  Percentage expenditure  Hepatitis B  Measles  ...  \\\n",
              "0             62     0.01               71.279624         65.0     1154  ...   \n",
              "1             64     0.01               73.523582         62.0      492  ...   \n",
              "2             66     0.01               73.219243         64.0      430  ...   \n",
              "3             69     0.01               78.184215         67.0     2787  ...   \n",
              "4             71     0.01                7.097109         68.0     3013  ...   \n",
              "\n",
              "   Polio  Total expenditure  Diphtheria   HIV/AIDS         GDP  Population  \\\n",
              "0    6.0               8.16         65.0       0.1  584.259210  33736494.0   \n",
              "1   58.0               8.18         62.0       0.1  612.696514    327582.0   \n",
              "2   62.0               8.13         64.0       0.1  631.744976  31731688.0   \n",
              "3   67.0               8.52         67.0       0.1  669.959000   3696958.0   \n",
              "4   68.0               7.87         68.0       0.1   63.537231   2978599.0   \n",
              "\n",
              "   Thinness 1-19 years  Thinness 5-9 years  Income composition of resources  \\\n",
              "0                 17.2                17.3                            0.479   \n",
              "1                 17.5                17.5                            0.476   \n",
              "2                 17.7                17.7                            0.470   \n",
              "3                 17.9                18.0                            0.463   \n",
              "4                 18.2                18.2                            0.454   \n",
              "\n",
              "   Schooling  \n",
              "0       10.1  \n",
              "1       10.0  \n",
              "2        9.9  \n",
              "3        9.8  \n",
              "4        9.5  \n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "life.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkj8eZGe8fYG"
      },
      "source": [
        "학습데이터 테스트데이터 나누기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iA-n0ijb8RZT"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPLNx2dv8apL"
      },
      "source": [
        "[문제1] 회기로(linear_regression) 수명 예측하기. 배점 10점"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qbMad6ka8Gxq"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "### [code] sklearn의 LinearRegression함수로 X_train을 학습하고 X_test의 수명을 예측하는 코드 만들기\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "life_regression = LinearRegression()\n",
        "life_regression.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DoaTnukV87-R"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE: 44.12654387814651\n"
          ]
        }
      ],
      "source": [
        "### [code] 예측한 X_test의 수명과 정답 y_test를 비교하여 mean square error 구하기\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "print('MSE:', mean_squared_error(y_test, life_regression.predict(X_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UQdiyl29NCx"
      },
      "source": [
        "[문제2] 분류로(knn) 수명 예측하기. 배점 15점\n",
        "\n",
        "sklearn의 knn함수는 default 하이퍼파라미터를 사용해야 합니다. 즉, 학습데이터와 레이블 이외에 하이퍼파라미터는 직접설정하지 말고 기본 값을 사용하도록 하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "685     78.5\n",
              "888     68.0\n",
              "1980    61.8\n",
              "776     73.6\n",
              "1148    72.5\n",
              "Name: Life expectancy, dtype: float64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1319,)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2S_iELyA9Zq0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "685     78.0\n",
              "888     68.0\n",
              "1980    62.0\n",
              "776     74.0\n",
              "1148    72.0\n",
              "Name: Life expectancy, dtype: float64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "### [code] sklearn의 knn함수로 X_train을 학습하고 X_test의 수명을 예측하는 코드 만들기\n",
        "### knn을 학습하기 위해서 y_train를 반올림하여 정수형태로 type-casting해야 함. 즉 기대수명을 소수점이 있는 81.72세가 아니라 반올림한 정수 82세로 바꿔야 함. 따라서 1세 단위로 class가 구분되는 것임. \n",
        "y_int_train = np.rint(y_train)\n",
        "y_int_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE: 62.98463636363636\n",
            "MSE: 94.71615151515152\n",
            "MSE: 103.43796969696969\n"
          ]
        }
      ],
      "source": [
        "knn1 = KNeighborsClassifier(n_neighbors=1)\n",
        "knn1.fit(X_train, y_int_train)\n",
        "print('MSE:', mean_squared_error(y_test, knn1.predict(X_test)))\n",
        "\n",
        "knn3 = KNeighborsClassifier(n_neighbors=3)\n",
        "knn3.fit(X_train, y_int_train)\n",
        "print('MSE:', mean_squared_error(y_test, knn3.predict(X_test)))\n",
        "\n",
        "knn5 = KNeighborsClassifier(n_neighbors=5)\n",
        "knn5.fit(X_train, y_int_train)\n",
        "print('MSE:', mean_squared_error(y_test, knn5.predict(X_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "f3ZcwoQr9ksG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "k=1 MSE: 62.98463636363636\n",
            "k=3 MSE: 94.71615151515152\n",
            "k=5 MSE: 103.43796969696969\n"
          ]
        }
      ],
      "source": [
        "### [code] 예측한 X_test의 수명과 정답 y_test를 비교하여 mean square error 구하기\n",
        "### k=1,3,5 일 때 각각의 accuracy성능을 구해야 함\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print('k=1 MSE:', mean_squared_error(y_test, knn1.predict(X_test)))\n",
        "print('k=3 MSE:', mean_squared_error(y_test, knn3.predict(X_test)))\n",
        "print('k=5 MSE:', mean_squared_error(y_test, knn5.predict(X_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DY0pyB9j76i7"
      },
      "source": [
        "#MNIST 숫자 이미지 예측하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVeQLxgDv6q0"
      },
      "source": [
        " MNIST dataset load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "AC6MV1H5cx8e"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "mnist = fetch_openml('mnist_784', cache=False)\n",
        "X = mnist.data.astype('float32')\n",
        "y = mnist.target.astype('int64')\n",
        "X /= 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SGSd-Zd73nZ"
      },
      "source": [
        "데이터 확인하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "3LkTyg0a03Uh",
        "outputId": "1de97053-3047-4d2a-897c-e872346f8062"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_example(X, y):\n",
        "    \"\"\"Plot the first 5 images and their labels in a row.\"\"\"\n",
        "    for i, (img, y) in enumerate(zip(X[:5].values.reshape(5, 28, 28), y[:5])):\n",
        "        plt.subplot(151 + i)\n",
        "        plt.imshow(img)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.title(y)\n",
        "plot_example(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QLCOPMNCw5bT"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeE8r8D0pYDt"
      },
      "source": [
        "[문제3] 분류로(KNN) 숫자 분류하기. 배점 10점\n",
        "\n",
        "sklearn의 knn함수는 default 하이퍼파라미터를 사용해야 합니다. 즉, 학습데이터와 레이블 이외에 하이퍼파라미터는 직접설정하지 말고 기본 값을 사용하도록 하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "oVHnskiIpXd-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9662142857142857\n"
          ]
        }
      ],
      "source": [
        "### [code] sklearn의 KNeighborsClassifier함수로 X_train을 학습하고 X_test의 레이블을 예측하는 코드 만들기\n",
        "knn = KNeighborsClassifier(n_neighbors=10)\n",
        "knn.fit(X_train, y_train)\n",
        "print('Accuracy:', accuracy_score(y_test, knn.predict(X_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "R-LJT_kR2Fo8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "k=1 Accuracy: 0.9703571428571428\n",
            "k=3 Accuracy: 0.9717857142857143\n",
            "k=5 Accuracy: 0.9693571428571428\n"
          ]
        }
      ],
      "source": [
        "### [code] 예측한 X_test 레이블의 accuracy(예측결과가 정답과 일치한 샘풀 숫자 / 전체 샘플 숫자) 구하기 (sklearn 이용가능)\n",
        "### k=1,3,5 일 때 각각의 accuracy성능을 구해야 함\n",
        "knn1 = KNeighborsClassifier(n_neighbors=1)\n",
        "knn1.fit(X_train, y_train)\n",
        "\n",
        "knn3 = KNeighborsClassifier(n_neighbors=3)\n",
        "knn3.fit(X_train, y_train)\n",
        "\n",
        "knn5 = KNeighborsClassifier(n_neighbors=5)\n",
        "knn5.fit(X_train, y_train)\n",
        "\n",
        "print('k=1 Accuracy:', accuracy_score(y_test, knn1.predict(X_test)))\n",
        "print('k=3 Accuracy:', accuracy_score(y_test, knn3.predict(X_test)))\n",
        "print('k=5 Accuracy:', accuracy_score(y_test, knn5.predict(X_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDZBMRXt2iJ6"
      },
      "source": [
        "[문제4] 회기로(linear_regression) 숫자 분류하기. 배점 15점"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "RMTfql9l2b-a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "### [code] sklearn의 LinearRegression함수로 X_train을 학습하고 X_test의 레이블을 예측하는 코드 만들기\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lin = LinearRegression()\n",
        "lin.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ELqs5GTr284h"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.22564285714285715\n"
          ]
        }
      ],
      "source": [
        "### [code] 예측한 X_test 레이블의 accuracy(예측결과가 정답과 일치한 샘풀 숫자 / 전체 샘플 숫자) 구하기 (sklearn 이용가능)\n",
        "### 이 때 예측결과는 반올림하여 정수로 type-casting해야 함\n",
        "y_pred = lin.predict(X_test)\n",
        "y_pred = np.rint(y_pred)\n",
        "\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f5_7jXg3ZfI"
      },
      "source": [
        "[문제5] KNN 알고리즘 직접 구현하기. 배점 20점\n",
        "\n",
        "이미 sklearn등 수 많은 라이브러리에서 기계학습 알고리즘이 제공되고 있습니다. 이들 라이브러리에서 함수를 사용하는 것이 간편하기는 하지만, 언젠가는 우리도 직접 알고리즘을 구현해야 할 필요가 있을 겁니다. 그래서 KNN알고리즘을 여러분들이 직접 구현하고 위 2가지 문제들, 1)수명예측 2)숫자분류, 에 적용하여 성능을 구해 보세요. 여러분들이 구현한 KNN 함수와 sklearn의 함수의 성능이 동일한지 확인해 보세요. 아주 약간의 차이가 있는 것은 괜찮습니다. KNN알고리즘에는 몇가지 하이퍼 파라미터 들이 있습니다. 아래 주소에서 어떤 하이퍼 파라미터 들이 있는지 알 수 있는데요. 이 하이퍼파라미터를 어떻게 사용하는지에 따라 성능이 약간 차이가 있습니다. \n",
        "sklearn의 KNN 함수 설명: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
        "\n",
        "최대한 sklearn의 knn함수와 동일한 하이퍼파라미터를 이용해서 비슷한 성능이 나오도록 하세요. 5%이내의 성능차이까지는 인정하도록 하겠습니다. 즉 sklearn의 knn함수와 비교해서 여러분이 만든 함수의 성능이 5%이내로 안 좋은 것은 문제를 제대로 푼 것으로 하겠습니다. 예를 들어 sklearn의 knn함수는 accuracy가 0.8이라고 한다면 0.8의 95%인 0.76이상인 것은 정답으로 인정하겠습니다. sklearn의 knn함수보다 여러분의 knn함수가 성능이 더 좋은 것은 범위에 관계 없이 다 정답입니다.\n",
        "\n",
        "sklearn의 knn함수는 default 하이퍼파라미터를 사용해야 합니다. 즉, 학습데이터와 레이블 이외에 하이퍼파라미터는 직접설정하지 말고 기본 값을 사용하도록 하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "class KNN():\n",
        "    n_neighbor = 5\n",
        "    def __init__(self, n_neighbor=5):\n",
        "        self.n_neighbor = n_neighbor\n",
        "\n",
        "    def fit(self, x, y):\n",
        "        self.X = x.to_numpy()\n",
        "        self.y = y.to_numpy()\n",
        "\n",
        "    def predict(self, x):\n",
        "        dist_list = self.X - x\n",
        "        dist_list = np.power(dist_list, 2)\n",
        "        dist_list = np.sqrt(np.sum(dist_list, 1))   # 기존 픽셀값과 x의 픽셀값을 각 요소별로 뺀 후, 제곱 후에 열을 합산 후 sqrt\n",
        "        neighbor = np.column_stack((dist_list, self.y))\n",
        "        neighbor = neighbor[neighbor[:, 0].argsort()]\n",
        "        # print(neighbor)\n",
        "        label_count = {}\n",
        "        for i in range(self.n_neighbor):\n",
        "            # print(neighbor[i][1])\n",
        "            if (neighbor[i][1] not in label_count.keys()):\n",
        "                label_count[neighbor[i][1]] = 1\n",
        "            else:\n",
        "                label_count[neighbor[i][1]] += 1\n",
        "\n",
        "        # print(label_count)\n",
        "        large = -1\n",
        "        large_label = -1\n",
        "        for key in label_count.keys():\n",
        "            if (label_count[key] > large):\n",
        "                large_label = key\n",
        "                large = label_count[key]\n",
        "        return large_label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 직접 개발한 KNN으로 수명 예측"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2837    68.0\n",
              "1152    71.0\n",
              "1456    70.0\n",
              "2580    72.0\n",
              "2372    67.0\n",
              "Name: Life expectancy, dtype: float64"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_loc = 'https://github.com/dknife/ML/raw/main/data/'\n",
        "life = pd.read_csv(data_loc + 'life_expectancy.csv')\n",
        "life.dropna(inplace = True)\n",
        "\n",
        "X = life[['Alcohol', 'Percentage expenditure', 'Polio',\n",
        "         'BMI', 'GDP', 'Thinness 1-19 years']]\n",
        "y = life['Life expectancy']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "y_int_train = np.rint(y_train)\n",
        "y_int_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "knn = KNN(n_neighbor=1)\n",
        "knn.fit(X_train, y_int_train)\n",
        "\n",
        "X_test_np = X_test.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "80.0"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "knn.predict(X_test_np[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = []\n",
        "for x in X_test_np:\n",
        "    y_pred.append(knn.predict(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Life expectancy MSE: 77.49836363636364\n"
          ]
        }
      ],
      "source": [
        "print('Life expectancy MSE:', mean_squared_error(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "knn1 = KNN(n_neighbor=1)\n",
        "knn1.fit(X_train, y_train)\n",
        "knn3 = KNN(n_neighbor=3)\n",
        "knn3.fit(X_train, y_train)\n",
        "knn5 = KNN(n_neighbor=5)\n",
        "knn5.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1NN Life expectancy MSE: 77.16736363636363\n"
          ]
        }
      ],
      "source": [
        "y_pred = []\n",
        "for x in X_test_np:\n",
        "    y_pred.append(knn1.predict(x))\n",
        "print('1NN Life expectancy MSE:', mean_squared_error(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3NN Life expectancy MSE: 77.07924242424242\n"
          ]
        }
      ],
      "source": [
        "y_pred = []\n",
        "for x in X_test_np:\n",
        "    y_pred.append(knn3.predict(x))\n",
        "print('3NN Life expectancy MSE:', mean_squared_error(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5NN Life expectancy MSE: 75.6850606060606\n"
          ]
        }
      ],
      "source": [
        "y_pred = []\n",
        "for x in X_test_np:\n",
        "    y_pred.append(knn5.predict(x))\n",
        "print('5NN Life expectancy MSE:', mean_squared_error(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 숫자 분류"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "mnist = fetch_openml('mnist_784', cache=False)\n",
        "X = mnist.data.astype('float32')\n",
        "y = mnist.target.astype('int64')\n",
        "X /= 255.0\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "knn1 = KNN(n_neighbor=1)\n",
        "knn1.fit(X_train, y_train)\n",
        "knn3 = KNN(n_neighbor=3)\n",
        "knn3.fit(X_train, y_train)\n",
        "knn5 = KNN(n_neighbor=5)\n",
        "knn5.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test_np = X_test.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_45832/2765130172.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX_test_np\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mknn1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'1NN Life expectancy MSE:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_45832/3403980952.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mdist_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mdist_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdist_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mdist_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdist_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# 기존 픽셀값과 x의 픽셀값을 각 요소별로 뺀 후, 제곱 후에 열을 합산 후 sqrt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mneighbor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdist_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "y_pred = []\n",
        "for x in X_test_np:\n",
        "    y_pred.append(knn1.predict(x))\n",
        "print('1NN Life expectancy MSE:', mean_squared_error(y_test, y_pred))\n",
        "\n",
        "y_pred = []\n",
        "for x in X_test_np:\n",
        "    y_pred.append(knn1.predict(x))\n",
        "print('3NN Life expectancy MSE:', mean_squared_error(y_test, y_pred))\n",
        "\n",
        "y_pred = []\n",
        "for x in X_test_np:\n",
        "    y_pred.append(knn1.predict(x))\n",
        "print('5NN Life expectancy MSE:', mean_squared_error(y_test, y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "중간고사_대체_레포트.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
